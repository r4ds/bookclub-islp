<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Notes – Introduction to Statistical Learning using Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03_video.html" rel="next">
<link href="./03_main.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e6f626c662a91eeead3924920b920f6f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="module">
  // When keyboard's 's' key is pressed, 
  // hide both sidebars (tables of contents)
  document.addEventListener(
    "keydown", 
    function (evt) {
      // Avoid keydown event repetition due to holding key
      if (evt.repeat) return;

      if ('s' === event.key.toLowerCase()) {
        const quartoContent = document.querySelector("#quarto-content");
        
        if (window.getComputedStyle(quartoContent).display === 'grid') {
          // Remove grid display
          quartoContent.style.display = "block";
          
          // Hide every HTML element, except for main content
          quartoContent
            .querySelectorAll(":scope > :not(.content, script)")
            .forEach(e => e.style.display = "none");
  
          // Change content margin for desktop view
          quartoContent
            .querySelector("main.content")
            .style.margin = "20px 100px";
        } else {
          // Try to restore Quarto's initial style
          quartoContent.style.display = "grid";

          quartoContent
            .querySelectorAll(":scope > :not(.content, script)")
            .forEach(e => e.style.display = "flex");

          quartoContent
            .querySelector("main.content")
            .style.margin = "21px 0";
        }
      }
    }
  );
</script> 

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./03_main.html">3. Linear Regression</a></li><li class="breadcrumb-item"><a href="./03_notes.html">Notes</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Statistical Learning using Python</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/r4ds/bookclub-islp" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./01_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. Introduction</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./02_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Statistical Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Applied Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./03_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Linear Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_notes.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./04_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Classification</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./05_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Resampling Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./06_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Linear Model Selection and Regularization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./07_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Moving Beyond Linearity</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./08_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. Tree-Based Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./09_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. Support Vector Machines</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./10_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./11_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Survival Analysis and Censored Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./12_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12. Unsupervised Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./13_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13. Multiple Testing</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Examples</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example_quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Example Quarto Document</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example_python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">NumPy</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./how-to.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to add to the book</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#questions-to-answer" id="toc-questions-to-answer" class="nav-link active" data-scroll-target="#questions-to-answer">Questions to Answer</a></li>
  <li><a href="#simple-linear-regression" id="toc-simple-linear-regression" class="nav-link" data-scroll-target="#simple-linear-regression">Simple Linear Regression</a>
  <ul class="collapse">
  <li><a href="#definition" id="toc-definition" class="nav-link" data-scroll-target="#definition">Definition</a></li>
  <li><a href="#visualization" id="toc-visualization" class="nav-link" data-scroll-target="#visualization">Visualization</a></li>
  <li><a href="#estimating-the-coefficients" id="toc-estimating-the-coefficients" class="nav-link" data-scroll-target="#estimating-the-coefficients">Estimating the Coefficients</a></li>
  <li><a href="#visualization-of-fit" id="toc-visualization-of-fit" class="nav-link" data-scroll-target="#visualization-of-fit">Visualization of Fit</a></li>
  <li><a href="#assessing-accuracy-of-coefficient-estimates" id="toc-assessing-accuracy-of-coefficient-estimates" class="nav-link" data-scroll-target="#assessing-accuracy-of-coefficient-estimates">Assessing Accuracy of Coefficient Estimates</a></li>
  <li><a href="#assessing-the-accuracy-of-the-model" id="toc-assessing-the-accuracy-of-the-model" class="nav-link" data-scroll-target="#assessing-the-accuracy-of-the-model">Assessing the Accuracy of the Model</a></li>
  </ul></li>
  <li><a href="#multiple-linear-regression" id="toc-multiple-linear-regression" class="nav-link" data-scroll-target="#multiple-linear-regression">Multiple Linear Regression</a>
  <ul class="collapse">
  <li><a href="#definition-1" id="toc-definition-1" class="nav-link" data-scroll-target="#definition-1">Definition</a></li>
  <li><a href="#important-questions-in-mlr" id="toc-important-questions-in-mlr" class="nav-link" data-scroll-target="#important-questions-in-mlr">Important Questions in MLR</a></li>
  </ul></li>
  <li><a href="#qualitative-predictors" id="toc-qualitative-predictors" class="nav-link" data-scroll-target="#qualitative-predictors">Qualitative Predictors</a></li>
  <li><a href="#extensions-to-the-linear-model" id="toc-extensions-to-the-linear-model" class="nav-link" data-scroll-target="#extensions-to-the-linear-model">Extensions to the Linear Model</a></li>
  <li><a href="#potential-problems" id="toc-potential-problems" class="nav-link" data-scroll-target="#potential-problems">Potential Problems</a></li>
  <li><a href="#answers-to-the-marketing-plan-questions" id="toc-answers-to-the-marketing-plan-questions" class="nav-link" data-scroll-target="#answers-to-the-marketing-plan-questions">Answers to the Marketing Plan questions</a></li>
  <li><a href="#comparison-of-linear-regression-with-k-nearest-neighbors" id="toc-comparison-of-linear-regression-with-k-nearest-neighbors" class="nav-link" data-scroll-target="#comparison-of-linear-regression-with-k-nearest-neighbors">Comparison of Linear Regression with K-Nearest Neighbors</a></li>
  <li><a href="#helpful-links" id="toc-helpful-links" class="nav-link" data-scroll-target="#helpful-links">Helpful links</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./03_main.html">3. Linear Regression</a></li><li class="breadcrumb-item"><a href="./03_notes.html">Notes</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Notes</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="questions-to-answer" class="level2">
<h2 class="anchored" data-anchor-id="questions-to-answer">Questions to Answer</h2>
<p>Recall the <code>Advertising</code> data from <strong>Chapter 2</strong>. Here are a few important questions that we might seek to address:</p>
<blockquote class="blockquote">
<p>Y = sales in thousands of $</p>
</blockquote>
<ol type="1">
<li><strong>Is there a relationship between advertising budget and sales?</strong></li>
<li><strong>How strong is the relationship between advertising budget and sales?</strong> Does knowledge of the advertising budget provide a lot of information about product sales?</li>
<li><strong>Which media are associated with sales?</strong></li>
<li><strong>How large is the association between each medium and sales?</strong> For every dollar spent on advertising in a particular medium, by what amount will sales increase?</li>
<li><strong>How accurately can we predict future sales?</strong></li>
<li><strong>Is the relationship linear?</strong> If there is approximately a straight-line relationship between advertising expenditure in the various media and sales, then linear regression is an appropriate tool. If not, then it may still be possible to transform the predictor or the response so that linear regression can be used.</li>
<li><strong>Is there synergy among the advertising media?</strong> Or, in stats terms, is there an interaction effect?</li>
</ol>
<p><strong>Linear regression can give an answer to all Qs!</strong></p>
</section>
<section id="simple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="simple-linear-regression">Simple Linear Regression</h2>
<ul>
<li>Supervised learning approach</li>
<li>Linear regression = Linear model</li>
<li><strong>Regression</strong> term is chosen due to historical reasons</li>
<li>Comes from “regression toward the mean”</li>
</ul>
<section id="definition" class="level3">
<h3 class="anchored" data-anchor-id="definition">Definition</h3>
<ul>
<li><strong>Simple linear regression:</strong> Very straightforward approach to predicting response <span class="math inline">\(Y\)</span> on predictor <span class="math inline">\(X\)</span></li>
<li>Assumes there’s approximately a linear relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span></li>
</ul>
<p><span class="math display">\[Y \approx \beta_{0} + \beta_{1}X\]</span></p>
<ul>
<li><p>Read “<span class="math inline">\(\approx\)</span>” as <em>“is approximately modeled by.”</em></p>
<ul>
<li>Also read: “regressing Y on X”</li>
</ul></li>
<li><p><span class="math inline">\(\beta_{0}\)</span> = intercept</p></li>
<li><p><span class="math inline">\(\beta_{1}\)</span> = slope</p></li>
<li><p><strong>Learned model</strong>: <span class="math inline">\(\hat{y}\)</span> = our prediction of <span class="math inline">\(Y\)</span> from <span class="math inline">\(x\)</span> and using <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{0}\)</span> <span class="math display">\[\hat{y} = \hat{\beta}_{0} + \hat{\beta}_{1}x\]</span></p></li>
<li><p><span class="math inline">\(x\)</span> = sample of <span class="math inline">\(X\)</span></p></li>
<li><p><span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{0}\)</span> are <strong>coefficients</strong> or <strong>parameters</strong></p>
<ul>
<li>They are estimated using the data (training data)</li>
<li><span class="math inline">\(\hat{\beta}_{0}\)</span> = our approximation of intercept</li>
<li><span class="math inline">\(\hat{\beta}_{1}\)</span> = our approximation of slope</li>
<li><strong>hat symbol</strong> ^ denotes “estimated value” for unknown parameters (i.e.&nbsp;something estimated through training)</li>
</ul></li>
</ul>
</section>
<section id="visualization" class="level3">
<h3 class="anchored" data-anchor-id="visualization">Visualization</h3>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/fig3_1.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>For the <code>Advertising</code> data, the least squares fit for the regression of <code>sales</code> onto <code>TV</code> is shown. The fit is found by minimizing the residual sum of squares (RSS). Each grey line segment represents a residual. In this case a linear fit captures the essence of the relationship, although it overestimates the trend in the left of the plot.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="estimating-the-coefficients" class="level3">
<h3 class="anchored" data-anchor-id="estimating-the-coefficients">Estimating the Coefficients</h3>
<ul>
<li><strong>Goal:</strong> Find <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> that makes <span class="math inline">\(\hat{y}\)</span> as close as possible to <span class="math inline">\(y\)</span></li>
<li><strong>How?</strong>: There are many ways to do this</li>
<li>Common approach is to minimize <em>least squares</em> criterion</li>
<li>In our case: <em>least squares</em> = <strong>residual sum of squares (RSS)</strong>
<ul>
<li>i.e.&nbsp;the metric we need to minimize</li>
</ul></li>
<li>In practice, computers do that!
<ul>
<li>e.g.&nbsp;<code>model.fit()</code></li>
</ul></li>
</ul>
<section id="residual-sum-of-squares-rss" class="level4">
<h4 class="anchored" data-anchor-id="residual-sum-of-squares-rss">Residual sum of squares (RSS)</h4>
<blockquote class="blockquote">
<p>Key ingrediant in the later quantities (<span class="math inline">\(R^2\)</span>, <span class="math inline">\(RSE\)</span>, <span class="math inline">\(F\)</span>)</p>
</blockquote>
<p>Let <span class="math inline">\(e_i = y_i - \hat{y_i}\)</span> (called <strong>residual</strong>), where <span class="math inline">\(i\)</span> is the index of of some value <span class="math inline">\(x_i\)</span> from <span class="math inline">\(X\)</span>.</p>
<p>Then: <span class="math display">\[\mathrm{RSS} = e^{2}_{1} + e^{2}_{2} + \ldots + e^{2}_{n}\]</span></p>
<p><span class="math display">\[\mathrm{RSS} = (y_{1} - \hat{\beta}_{0} - \hat{\beta}_{1}x_{1})^{2} + (y_{2} - \hat{\beta}_{0} - \hat{\beta}_{1}x_{2})^{2} + \ldots + (y_{n} - \hat{\beta}_{0} - \hat{\beta}_{1}x_{n})^{2}\]</span></p>
<p>Least squares approachs chooses <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> to minimize <span class="math inline">\(RSS\)</span>:</p>
<p><span class="math display">\[\hat{\beta}_{1} = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}\]</span></p>
<p><span class="math display">\[\hat{\beta}_{0} = \bar{y} - \hat{\beta}_{1}\bar{x}\]</span></p>
<ul>
<li><span class="math inline">\(\bar{x}\)</span>, <span class="math inline">\(\bar{y}\)</span> = sample means of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span></li>
</ul>
</section>
</section>
<section id="visualization-of-fit" class="level3">
<h3 class="anchored" data-anchor-id="visualization-of-fit">Visualization of Fit</h3>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/fig3_2.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Contour and three-dimensional plots of the RSS on the <code>Advertising</code> data, using <code>sales</code> as the response and <code>TV</code> as the predictor. The red dots correspond to the least squares estimates <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span>, given by (3.4).</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="assessing-accuracy-of-coefficient-estimates" class="level3">
<h3 class="anchored" data-anchor-id="assessing-accuracy-of-coefficient-estimates">Assessing Accuracy of Coefficient Estimates</h3>
<p>Back to our initial assumption (in another notation w/o “<span class="math inline">\(\approx\)</span>”): <span class="math display">\[Y = \beta_{0} + \beta_{1}X + \epsilon\]</span></p>
<ul>
<li>This is called the <em>population regression line</em>
<ul>
<li>The best approximation under linearity assumption</li>
</ul></li>
<li>Why do we want to assess accuracy of coefficient estimates?
<ul>
<li><span class="math inline">\(\hat\beta_0\)</span> defines the <strong>slope</strong> = slope implies some relationship which need to be assessed statistically</li>
</ul></li>
<li><span class="math inline">\(\epsilon\)</span>: irreducible error term
<ul>
<li><strong>Assumption 1</strong>: <span class="math inline">\(\epsilon \sim N(0,\sigma^2)\)</span></li>
<li><strong>Assumption 2</strong>: <span class="math inline">\(\epsilon\)</span> is independent of <span class="math inline">\(X\)</span></li>
<li>It’s here for many reasons (mostly due to our limited knoledge about the REAL relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>)</li>
<li>“<a href="https://en.wikipedia.org/wiki/All_models_are_wrong">All models are wrong, but some are useful</a>” - George Box</li>
</ul></li>
<li>Problem:
<ul>
<li><span class="math inline">\(Y\)</span> is a random variable with population mean <span class="math inline">\(\mu\)</span></li>
<li><span class="math inline">\(\hat{y}\)</span> is a random variable with sample mean <span class="math inline">\(\hat{\mu}\)</span> (estimated using data)</li>
<li><strong>How accurate is the as an estimate of <span class="math inline">\(\mu\)</span>?</strong></li>
<li>This is answered by finding the <strong>standard error</strong> (<span class="math inline">\(SE\)</span>) for coefficients</li>
</ul></li>
</ul>
<section id="standard-error-of-regression-coefficients" class="level4">
<h4 class="anchored" data-anchor-id="standard-error-of-regression-coefficients">Standard error of regression coefficients</h4>
<ul>
<li>Residual standard error (RSE): will be used later to find <span class="math inline">\(SE\)</span></li>
</ul>
<p><span class="math display">\[\mathrm{RSE} = \sqrt{\frac{\mathrm{RSS}}{n - 2}}\]</span></p>
<p>where <span class="math inline">\(n\)</span> is the sample size - Standard error assoicated with <span class="math inline">\(\hat{\beta}_{0}\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span>: <span class="math display">\[\mathrm{SE}(\hat\beta_0)^2 = \sigma^2 \left[\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2}\right]\]</span></p>
<p><span class="math display">\[\mathrm{SE}(\hat\beta_1)^2 = \frac{\sigma^2}{\sum_{i=1}^n (x_i - \bar{x})^2}\]</span></p>
<ul>
<li><strong>95% confidence interval:</strong>
<ul>
<li>a range of values such that with 95% probability, the range will contain the true unknown value of the parameter</li>
<li>“95” is just a common number</li>
</ul></li>
<li>The 95% CI limits are formed by:</li>
</ul>
<p><span class="math display">\[\hat\beta_1 \pm 2\ \cdot \ \mathrm{SE}(\hat\beta_1)\]</span></p>
<p><span class="math display">\[\hat\beta_0 \pm 2\ \cdot \ \mathrm{SE}(\hat\beta_0)\]</span></p>
<ul>
<li>Figure below can be read: “<em>there’s approximately 95% chance that the shaded area will contain the true value of <span class="math inline">\(\beta\)</span></em>”</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/03-95-percent-confidence-interval.jpg" class="img-fluid figure-img"></p>
<figcaption>Source: https://mathblog.com/statistics/definitions/confidence-interval/95-ci/</figcaption>
</figure>
</div>
</section>
<section id="using-se-in-hypothesis-testing" class="level4">
<h4 class="anchored" data-anchor-id="using-se-in-hypothesis-testing">Using SE in hypothesis testing</h4>
<ul>
<li>For any estimated coefficient <span class="math inline">\(\hat{\beta}\)</span>:
<ol type="1">
<li>Formulate a null hypothesis <span class="math inline">\(H_0\)</span> vs.&nbsp;alternative hypothesis <span class="math inline">\(H_a\)</span> about <span class="math inline">\(\hat{\beta}\)</span></li>
<li>Estimate <span class="math inline">\(SE\)</span></li>
<li>Compute <em>t-statistic</em>: <span class="math display">\[t = \frac{\hat{\beta}}{SE(\hat{\beta})}\]</span></li>
<li>Use t-statistic to find the p-value = <span class="math inline">\(Pr(|t|)\)</span></li>
<li>p-value is used to decide whether we reject null hypothesis or not</li>
</ol></li>
<li><span class="math inline">\(H_0\)</span> is rejected if p-value &lt; <span class="math inline">\(\alpha\)</span>
<ul>
<li><span class="math inline">\(\alpha\)</span> significance level: the common choice is 0.05, but this cutoff vary based on context</li>
<li>if the p-value of some coefficient &lt; <span class="math inline">\(\alpha\)</span>, then we say it has <strong>significant</strong> effect on <span class="math inline">\(Y\)</span></li>
<li>otherwise, we say it has <strong>insignificant</strong> effect on <span class="math inline">\(Y\)</span></li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/03-table3_1.png" class="img-fluid figure-img"></p>
<figcaption>Table 3.1</figcaption>
</figure>
</div>
<ul>
<li>e.g.&nbsp;<span class="math inline">\(H_0\)</span> : There is no relationship between ad. on TV and the increase in sales
<ul>
<li><span class="math inline">\(\rightarrow\)</span> slope is approximately 0</li>
<li><span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_1\)</span> = 0</li>
</ul></li>
<li>Easy to do using Python or R</li>
<li>More details in chapter 13</li>
</ul>
</section>
</section>
<section id="assessing-the-accuracy-of-the-model" class="level3">
<h3 class="anchored" data-anchor-id="assessing-the-accuracy-of-the-model">Assessing the Accuracy of the Model</h3>
<blockquote class="blockquote">
<p>i.e.&nbsp;Model Evaluation</p>
</blockquote>
<ul>
<li>Accuracy of the model = Quality of a linear regression fit</li>
<li>There are four quantities for that:
<ol type="1">
<li><strong>Residual standard error</strong> (<span class="math inline">\(RSE\)</span>)</li>
<li><span class="math inline">\(R^2\)</span> <strong>statistic</strong></li>
<li>Pearson correlation coefficient (<span class="math inline">\(r=Cor(X,Y)\)</span>)</li>
<li><span class="math inline">\(F\)</span>-<strong>statistic</strong> (discussed in next section)</li>
</ol></li>
<li><strong>RSE</strong>: <span class="math display">\[\mathrm{RSE} = \sqrt{\frac{\mathrm{RSS}}{n - 2}}\]</span>
<ul>
<li><strong>Interpretation:</strong> <em>absolute measure of the lack of fit of the model</em></li>
<li><strong>small value</strong> = model fits the data well</li>
<li>measured in the unit of <span class="math inline">\(Y\)</span> (e.g.&nbsp;RSE = 3.2 units sold)</li>
</ul></li>
<li><em><span class="math inline">\(R^2\)</span></em> statistic (a.k.a coefficient of determination): <span class="math display">\[R^2 = 1 - \frac{RSS}{TSS}\]</span> where TSS is the <strong>total sum of squares</strong>: <span class="math display">\[TSS = \Sigma (y_i - \bar{y})^2\]</span>
<ul>
<li><strong>Interpretation:</strong> <em>proportion of the variance in <span class="math inline">\(Y\)</span> explained by using some predictor <span class="math inline">\(X\)</span></em></li>
<li>a <em>good value</em> depends on the application.</li>
<li>ranges from 0 to 1 (<a href="https://www.graphpad.com/support/faq/how-can-rsup2sup-be-negative/">can be negative in extreme cases?</a>)</li>
</ul></li>
<li>Pearson correlation coefficient (<span class="math inline">\(r=Cor(X,Y)\)</span>) <span class="math display">\[r = Cor(X,Y) = \frac{\sum{(x_i - \bar{x})(y_i - \bar{y})}}{\sqrt{\sum{(x_i - \bar{x})^2} \sum{(y_i - \bar{y})^2}}}\]</span>
<ul>
<li><span class="math inline">\(R^2=r^2\)</span> in simple linear regression</li>
</ul></li>
</ul>
</section>
</section>
<section id="multiple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="multiple-linear-regression">Multiple Linear Regression</h2>
<section id="definition-1" class="level3">
<h3 class="anchored" data-anchor-id="definition-1">Definition</h3>
<p><strong>Multiple linear regression</strong> extends simple linear regression for <em>p</em> predictors:</p>
<p><span class="math display">\[Y = \beta_{0} + \beta_{1}X_1 + \beta_{2}X_2 + ... +\beta_{p}X_p + \epsilon_i\]</span></p>
<ul>
<li><p><span class="math inline">\(\beta_{j}\)</span> is the <em>average</em> effect on <span class="math inline">\(Y\)</span> from <span class="math inline">\(X_{j}\)</span> holding all other predictors fixed.</p>
<ul>
<li>But this is not the case in reality! (e.g.&nbsp;using weight and height as predictors in some model)</li>
</ul></li>
<li><p>For <span class="math inline">\(p=2\)</span> predictors, the model represents a plane in the 3D space instead of a line <img src="images\03-fig3_4.png" class="img-fluid" alt="Figure 3.4 in ISLP"> <span class="math display">\[\hat{y} = \hat{\beta_{0}} + \hat{\beta_{1}}x_1 + \hat{\beta_{2}}x_2 + ... + \hat{\beta_{p}}x_p\]</span></p></li>
<li><p>As in the simple case, we aim to choose the set of coefficients <span class="math inline">\(\hat{\beta_{0}}, \hat{\beta_{1}}, ..., \hat{\beta_{p}}\)</span> that minimizes the <span class="math inline">\(RSS\)</span> when making predictions using <span class="math inline">\(\hat{y}\)</span></p></li>
<li><p>In this section, we assume predictors are <strong>independent</strong> of each others</p></li>
<li><p>Important notes (<a href="https://www.youtube.com/watch?v=o9hoLdylWKo&amp;list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ&amp;index=15">from lecture 3</a>)</p>
<ul>
<li>Ideal scenario (i.e.&nbsp;balanced design): Predictors are uncorrelated</li>
<li>Correlations amongst predictors cause problems
<ul>
<li>When a change on some predictor <span class="math inline">\(X_j\)</span> changes everything else, coefficient intepretations become hazardous</li>
<li>Makes thing complicated when discussing <strong>causality</strong></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="important-questions-in-mlr" class="level3">
<h3 class="anchored" data-anchor-id="important-questions-in-mlr">Important Questions in MLR</h3>
<blockquote class="blockquote">
<p>More variables/predictors <span class="math inline">\(\rightarrow\)</span> More things to assess!</p>
</blockquote>
<ol type="1">
<li><p><strong>Relationship between the resposne and predictors:</strong> <em>Is at least one of the predictors <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, … , <span class="math inline">\(X_p\)</span> useful in predicting the response?</em></p>
<ol type="a">
<li>formulate a null hypothesis <span class="math inline">\(H_0: \beta_1 = \beta_2 = ... = \beta_p = 0\)</span></li>
<li>compute <span class="math inline">\(F\)</span>-statistic <span class="math display">\[F = \frac{(TSS-RSS)/p}{RSS/(n-p-1)}\]</span></li>
<li>use it to find p-value (all of that can be don using computers)</li>
</ol></li>
<li><p><strong>Deciding on important variables to include in the model:</strong> <em>Do all the predictors help to explain <span class="math inline">\(Y\)</span> , or is only a subset of the predictors useful?</em></p>
<ul>
<li>a.k.a. Model Selection Problem</li>
<li><strong>Option 1</strong>: test all possibilities and choose the best subset (inefficient with many variables w/ <span class="math inline">\(2^p\)</span> possible models)</li>
<li><strong>Option 2</strong>: use a <strong>variable selection</strong> algorithm (Forward - Backward - Mixed)
<ul>
<li>Discussed in detail in Chapter 6</li>
</ul></li>
</ul></li>
<li><p><strong>Model evaluation:</strong> <em>How well does the model fit the data?</em></p>
<ul>
<li><strong><span class="math inline">\(R^2\)</span></strong> still gives <em>proportion of the variance explained</em>
<ul>
<li>Adding predictors w/ no association to <span class="math inline">\(Y\)</span> can reducde <span class="math inline">\(R^2\)</span> but results in overfitting</li>
</ul></li>
<li>Can also look at <strong>RSE</strong> which is generalized for multiple regression as: <span class="math display">\[RSE = \sqrt{\frac{1}{n-p-1}RSS}\]</span></li>
</ul></li>
<li><p><strong>Making and assising predictions:</strong> <em>Given a set of predictor values, what response value should we predict, and how accurate is our prediction?</em></p>
<p>Three sets of uncertainty in predictions:</p>
<ul>
<li>Uncertainty in <span class="math inline">\(\hat{\beta_i}\)</span> the estimates of <span class="math inline">\(\beta_i\)</span> (use <strong>confidence interval</strong>)</li>
<li>Model bias (i.e.&nbsp;inductive bias): casued by our assumptions</li>
<li>Irreducible error <span class="math inline">\(\epsilon\)</span> (use <strong>prediction interval</strong>): even if we know the true <span class="math inline">\(\beta_i\)</span>, there is still <span class="math inline">\(\epsilon\)</span>!
<ul>
<li>PI is wider than CI because it incorporates all all kinds of errors.</li>
</ul></li>
</ul></li>
</ol>
</section>
</section>
<section id="qualitative-predictors" class="level2">
<h2 class="anchored" data-anchor-id="qualitative-predictors">Qualitative Predictors</h2>
<blockquote class="blockquote">
<p>a.k.a. <em>categorical predictors</em> or <em>factor variables</em></p>
</blockquote>
<ul>
<li><strong>Dummy variables</strong> (a.k.a. one-hot encoding): if there are <span class="math inline">\(k\)</span> levels, introduce <span class="math inline">\(k-1\)</span> dummy variables which are equal to one when the underlying qualitative predictor takes that value.</li>
<li>For example if there are 3 levels, introduce 2 new dummy variables (<span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>) and fit the model:</li>
</ul>
<p><span class="math display">\[y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \epsilon_i\]</span></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Qualitative Predicitor</th>
<th style="text-align: center;"><span class="math inline">\(x_{i1}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(x_{i2}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>level 0 (baseline)</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>level 1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>level 2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<ul>
<li>Coefficients are interpreted the average effect relative to the baseline.</li>
</ul>
</section>
<section id="extensions-to-the-linear-model" class="level2">
<h2 class="anchored" data-anchor-id="extensions-to-the-linear-model">Extensions to the Linear Model</h2>
<ul>
<li><strong>Interaction/Synergy Effects</strong>
<ul>
<li><p>Remove the previous assumptions about independence among predictors (additive assumption)</p></li>
<li><p>Add a product term <span class="math inline">\(X_1 \times X_2\)</span> with its own coefficient <span class="math inline">\(\beta_3\)</span> to model how the relationship between <span class="math inline">\(Y\)</span> and one variable <span class="math inline">\(X_1\)</span> changes depending on the value of the other variable <span class="math inline">\(X_2\)</span>: <span class="math display">\[Y = \beta_{0} + \beta_{1}X_1 + \beta_{2}X_2 + \beta_{3}(X_1 \cdot X_2) + \epsilon_i\]</span></p>
<ul>
<li>There are many possibilities (e.g.&nbsp;interaction between quant. and qualit. variables)</li>
</ul></li>
</ul></li>
<li>Non-linear relationships (e.g.&nbsp;polynomial fits)</li>
</ul>
<p><span class="math display">\[Y = \beta_{0} + \beta_{1}X + \beta_{2}X^2 + ... \beta_{n}X^n + \epsilon_i\]</span></p>
</section>
<section id="potential-problems" class="level2">
<h2 class="anchored" data-anchor-id="potential-problems">Potential Problems</h2>
<blockquote class="blockquote">
<p>Common problems with linear models and tips to address them</p>
</blockquote>
<ol type="1">
<li><p><em>Non-linear relationships</em> <img src="images/03-fig3_9.png" class="img-fluid" alt="Figure 3.9"></p>
<ul>
<li>Residual plots are useful tool to see if any remaining trends exist.</li>
<li>If a non-linear associations are observed, consider transformaing predictors before fitting (e.g.&nbsp;<span class="math inline">\(log X\)</span>)</li>
</ul></li>
<li><p><em>Correlation of Error Terms</em></p>
<p>Linear regression assumes that the error terms <span class="math inline">\(\epsilon_i\)</span> are uncorrelated. Residuals may indicate that this is not correct (obvious <em>tracking</em> in the data). One could also look at the autocorrelation of the residuals (e.g.&nbsp;time-series).</p></li>
<li><p><em>Non-constant variance of error terms</em></p>
<p>Again this can be revealed by examining the residuals. Consider transformation of the predictors to remove non-constant variance. The figure below shows residuals demonstrating non-constant variance, and shows this being mitigated to a great extent by log transforming the data.</p></li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/fig3_11.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Figure 3.11</figcaption>
</figure>
</div>
</div>
</div>
<ol start="4" type="1">
<li><p><em>Outliers</em></p>
<ul>
<li>Observations for which <span class="math inline">\(y_i\)</span> is unusual given <span class="math inline">\(x_i\)</span> (see point ‘20’ in figure 3.12)</li>
<li>Often outliers are mistakes in data collection and can be removed, but could also be an indicator of a deficient model.<br>
</li>
<li>Detect outliers by plotting studentized residuals (residual <span class="math inline">\(e_i\)</span> divided by the estimated error) and look for residuals larger then 3 standard deviations in absolute value.</li>
<li>An outlier may not effect the fit much but can have dramatic effect on the <strong>RSE</strong>.</li>
<li>We need to identify these before fitting the model</li>
</ul></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/03-fig3_12.png" class="img-fluid figure-img"></p>
<figcaption>Figure 3.12</figcaption>
</figure>
</div>
<ol start="5" type="1">
<li><p><em>High Leverage Points</em></p>
<ul>
<li>These are points with unusual values of <span class="math inline">\(x_i\)</span> (see point ‘41’ in figure 3.13)</li>
<li>These points can have large impact on the fit, as in the example, including point 41 pulls slope up significantly.</li>
<li>Use <em>leverage statistic</em> to identify high leverage points before fitting the model, which can be hard to identify in multiple regression.</li>
</ul></li>
</ol>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/fig3_13.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Figure 3.13</figcaption>
</figure>
</div>
</div>
</div>
<ol start="6" type="1">
<li><p><em>Collinearity</em></p>
<ul>
<li><p>Two predictor variables are closely related to one another.</p></li>
<li><p>The problem is that it’s difficult to separate out the individual effect of each one on the reponse.</p></li>
<li><p>Often can be addressed with by:</p>
<ol type="1">
<li>Dropping one of the highly correlated predictors or</li>
<li>Combining correlated predictors into one variable.</li>
</ol></li>
<li><p><em>Multicollinearity</em> (collinearity involving 3 or more predictors) is not so easy to identify.</p>
<ul>
<li><p>Use <em>Variance inflation factor</em>, which is the ratio of the variance of <span class="math inline">\(\hat{\beta_j}\)</span> when fitting the full model to fitting the parameter on its own. Can be computed using the formula: <span class="math display">\[VIF(\hat{\beta_j}) = \frac{1}{1-R^2_{X_j|X_{-j}}}\]</span></p>
<ul>
<li>where <span class="math inline">\(R^2_{X_j|X_{-j}}\)</span> is the <span class="math inline">\(R^2\)</span> from a regression of <span class="math inline">\(X_j\)</span> onto all the other predictors.</li>
<li>large <span class="math inline">\(VIF\)</span> indicates the presence of collinearty</li>
</ul></li>
</ul></li>
</ul></li>
</ol>
</section>
<section id="answers-to-the-marketing-plan-questions" class="level2">
<h2 class="anchored" data-anchor-id="answers-to-the-marketing-plan-questions">Answers to the Marketing Plan questions</h2>
<ol type="1">
<li><p><strong>Is there a relationship between advertising budget and sales?</strong></p>
<p>Tool: Multiple regression, look at F-statistic.</p></li>
<li><p><strong>How strong is the relationship between advertising budget and sales?</strong></p>
<p>Tool: <strong><span class="math inline">\(R^2\)</span></strong> and <strong>RSE</strong></p></li>
<li><p><strong>Which media are associated with sales?</strong></p>
<p>Tool: model selection approaches e.g.&nbsp;p-values for each predictor’s <em>t-statistic</em>. Explored further in chapter 6.</p></li>
<li><p><strong>How large is the association between each medium and sales?</strong></p>
<p>Tool: Confidence intervals on <span class="math inline">\(\hat{\beta_j}\)</span>. Narrow CI is a strong evidence for association</p></li>
<li><p><strong>How accurately can we predict future sales?</strong></p>
<p>Tool: Prediction intervals for individual response, confidence intervals for average response.</p></li>
<li><p><strong>Is the relationship linear?</strong></p>
<p>Tool: Residual Plots</p></li>
<li><p><strong>Is there synergy among the advertising media?</strong></p>
<p>Tool: Interaction terms and the significance of interaction term’s coefficient.</p></li>
</ol>
</section>
<section id="comparison-of-linear-regression-with-k-nearest-neighbors" class="level2">
<h2 class="anchored" data-anchor-id="comparison-of-linear-regression-with-k-nearest-neighbors">Comparison of Linear Regression with K-Nearest Neighbors</h2>
<ul>
<li>This section examines the K-nearest neighbor (KNN) method (a non-parameteric method).</li>
<li>Non-parametric methods doesn’t make assumptions about the form of <span class="math inline">\(f(X)\)</span> (e.g.&nbsp;linearity)</li>
<li>This is essentially a <span class="math inline">\(K\)</span>-point moving average.</li>
</ul>
<p><img src="images/03-fig3_16.png" class="img-fluid"></p>
<ul>
<li><span class="math inline">\(K\)</span> determines the model smoothness
<ul>
<li>Small value: low bias &amp; high variance</li>
<li>High value: high bias &amp; low variance</li>
</ul></li>
<li>This serves to illustrate the Bias-Variance trade-off nicely.</li>
<li>However, parameteric methods outperform non-parameteric methods if the assumptions made were close to the true <span class="math inline">\(f(X)\)</span>.</li>
</ul>
</section>
<section id="helpful-links" class="level2">
<h2 class="anchored" data-anchor-id="helpful-links">Helpful links</h2>
<ul>
<li><a href="https://mlu-explain.github.io/linear-regression/">https://mlu-explain.github.io/linear-regression/</a></li>
<li><a href="https://observablehq.com/@yizhe-ang/interactive-visualization-of-linear-regression">https://observablehq.com/<span class="citation" data-cites="yizhe-ang/interactive-visualization-of-linear-regression">@yizhe-ang/interactive-visualization-of-linear-regression</span></a></li>
</ul>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/hastie\.su\.domains\/ISLP\/ISLP_website\.pdf");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./03_main.html" class="pagination-link" aria-label="3. Linear Regression">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">3. Linear Regression</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./03_video.html" class="pagination-link" aria-label="Video">
        <span class="nav-page-text">Video</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1"></a><span class="fu"># Notes {-}</span></span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="fu">## Questions to Answer</span></span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a>Recall the <span class="in">`Advertising`</span> data from **Chapter 2**. Here are a few important questions that we might seek to address:</span>
<span id="cb1-6"><a href="#cb1-6"></a></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="at">&gt; Y = sales in thousands of $</span></span>
<span id="cb1-8"><a href="#cb1-8"></a></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="ss">1. </span>**Is there a relationship between advertising budget and sales?**</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="ss">2. </span>**How strong is the relationship between advertising budget and sales?** Does knowledge of the advertising budget provide a lot of information about product sales?</span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="ss">3. </span>**Which media are associated with sales?**</span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="ss">4. </span>**How large is the association between each medium and sales?** For every dollar spent on advertising in a particular medium, by what amount will sales increase? </span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="ss">5. </span>**How accurately can we predict future sales?**</span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="ss">6. </span>**Is the relationship linear?** If there is approximately a straight-line relationship between advertising expenditure in the various media and sales, then linear regression is an appropriate tool. If not, then it may still be possible to transform the predictor or the response so that linear regression can be used.</span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="ss">7. </span>**Is there synergy among the advertising media?** Or, in stats terms, is there an interaction effect?</span>
<span id="cb1-16"><a href="#cb1-16"></a></span>
<span id="cb1-17"><a href="#cb1-17"></a>**Linear regression can give an answer to all Qs!**</span>
<span id="cb1-18"><a href="#cb1-18"></a></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="fu">## Simple Linear Regression</span></span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="ss">- </span>Supervised learning approach</span>
<span id="cb1-21"><a href="#cb1-21"></a><span class="ss">- </span>Linear regression = Linear model</span>
<span id="cb1-22"><a href="#cb1-22"></a><span class="ss">- </span>**Regression** term is chosen due to historical reasons</span>
<span id="cb1-23"><a href="#cb1-23"></a><span class="ss">- </span>Comes from "regression toward the mean"</span>
<span id="cb1-24"><a href="#cb1-24"></a></span>
<span id="cb1-25"><a href="#cb1-25"></a><span class="fu">### Definition</span></span>
<span id="cb1-26"><a href="#cb1-26"></a><span class="ss">- </span>**Simple linear regression:** Very straightforward approach to predicting response $Y$ on predictor $X$</span>
<span id="cb1-27"><a href="#cb1-27"></a><span class="ss">- </span>Assumes there's approximately a linear relationship between $Y$ and $X$</span>
<span id="cb1-28"><a href="#cb1-28"></a></span>
<span id="cb1-29"><a href="#cb1-29"></a>$$Y \approx \beta_{0} + \beta_{1}X$$</span>
<span id="cb1-30"><a href="#cb1-30"></a></span>
<span id="cb1-31"><a href="#cb1-31"></a><span class="ss">- </span>Read "$\approx$" as *"is approximately modeled by."*</span>
<span id="cb1-32"><a href="#cb1-32"></a><span class="ss">    - </span>Also read: "regressing Y on X"</span>
<span id="cb1-33"><a href="#cb1-33"></a><span class="ss">- </span>$\beta_{0}$ = intercept</span>
<span id="cb1-34"><a href="#cb1-34"></a><span class="ss">- </span>$\beta_{1}$ = slope</span>
<span id="cb1-35"><a href="#cb1-35"></a></span>
<span id="cb1-36"><a href="#cb1-36"></a><span class="ss">- </span>**Learned model**: $\hat{y}$ = our prediction of $Y$ from $x$ and using $\hat{\beta}_{0}$ and $\hat{\beta}_{0}$</span>
<span id="cb1-37"><a href="#cb1-37"></a>$$\hat{y} = \hat{\beta}_{0} + \hat{\beta}_{1}x$$</span>
<span id="cb1-38"><a href="#cb1-38"></a></span>
<span id="cb1-39"><a href="#cb1-39"></a><span class="ss">- </span>$x$ = sample of $X$</span>
<span id="cb1-40"><a href="#cb1-40"></a><span class="ss">- </span>$\hat{\beta}_{0}$ and $\hat{\beta}_{0}$ are **coefficients** or **parameters**</span>
<span id="cb1-41"><a href="#cb1-41"></a><span class="ss">    - </span>They are estimated using the data (training data)</span>
<span id="cb1-42"><a href="#cb1-42"></a><span class="ss">    - </span>$\hat{\beta}_{0}$ = our approximation of intercept</span>
<span id="cb1-43"><a href="#cb1-43"></a><span class="ss">    - </span>$\hat{\beta}_{1}$ = our approximation of slope</span>
<span id="cb1-44"><a href="#cb1-44"></a><span class="ss">    - </span>**hat symbol** ^ denotes "estimated value" for unknown parameters (i.e. something estimated through training)</span>
<span id="cb1-45"><a href="#cb1-45"></a></span>
<span id="cb1-46"><a href="#cb1-46"></a></span>
<span id="cb1-47"><a href="#cb1-47"></a></span>
<span id="cb1-48"><a href="#cb1-48"></a><span class="fu">### Visualization</span></span>
<span id="cb1-49"><a href="#cb1-49"></a></span>
<span id="cb1-52"><a href="#cb1-52"></a><span class="in">```{r}</span></span>
<span id="cb1-53"><a href="#cb1-53"></a><span class="co">#| label: fig3-1</span></span>
<span id="cb1-54"><a href="#cb1-54"></a><span class="co">#| echo: false</span></span>
<span id="cb1-55"><a href="#cb1-55"></a><span class="co">#| fig-cap: For the `Advertising` data, the least squares fit for the regression of `sales` onto `TV` is shown. The fit is found by minimizing the residual sum of squares (RSS). Each grey line segment represents a residual. In this case a linear fit captures the essence of the relationship, although it overestimates the trend in the left of the plot.</span></span>
<span id="cb1-56"><a href="#cb1-56"></a><span class="co">#| out-width: 100%</span></span>
<span id="cb1-57"><a href="#cb1-57"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"images/fig3_1.jpg"</span>)</span>
<span id="cb1-58"><a href="#cb1-58"></a><span class="in">```</span></span>
<span id="cb1-59"><a href="#cb1-59"></a></span>
<span id="cb1-60"><a href="#cb1-60"></a><span class="fu">### Estimating the Coefficients</span></span>
<span id="cb1-61"><a href="#cb1-61"></a><span class="ss">- </span>**Goal:** Find $\hat{\beta}_{0}$ and $\hat{\beta}_{1}$ that makes $\hat{y}$ as close as possible to $y$</span>
<span id="cb1-62"><a href="#cb1-62"></a><span class="ss">- </span>**How?**: There are many ways to do this</span>
<span id="cb1-63"><a href="#cb1-63"></a><span class="ss">- </span>Common approach is to minimize *least squares* criterion </span>
<span id="cb1-64"><a href="#cb1-64"></a><span class="ss">- </span>In our case: *least squares* = **residual sum of squares (RSS)**</span>
<span id="cb1-65"><a href="#cb1-65"></a><span class="ss">    - </span>i.e. the metric we need to minimize </span>
<span id="cb1-66"><a href="#cb1-66"></a><span class="ss">- </span>In practice, computers do that! </span>
<span id="cb1-67"><a href="#cb1-67"></a><span class="ss">    - </span>e.g. <span class="in">`model.fit()`</span></span>
<span id="cb1-68"><a href="#cb1-68"></a></span>
<span id="cb1-69"><a href="#cb1-69"></a><span class="fu">#### Residual sum of squares (RSS)</span></span>
<span id="cb1-70"><a href="#cb1-70"></a><span class="at">&gt; Key ingrediant in the later quantities ($R^2$, $RSE$, $F$)</span></span>
<span id="cb1-71"><a href="#cb1-71"></a></span>
<span id="cb1-72"><a href="#cb1-72"></a>Let $e_i = y_i - \hat{y_i}$ (called **residual**), where $i$ is the index of of some value $x_i$ from $X$.</span>
<span id="cb1-73"><a href="#cb1-73"></a></span>
<span id="cb1-74"><a href="#cb1-74"></a>Then:</span>
<span id="cb1-75"><a href="#cb1-75"></a>$$\mathrm{RSS} = e^{2}_{1} + e^{2}_{2} + \ldots + e^{2}_{n}$$</span>
<span id="cb1-76"><a href="#cb1-76"></a></span>
<span id="cb1-77"><a href="#cb1-77"></a>$$\mathrm{RSS} = (y_{1} - \hat{\beta}_{0} - \hat{\beta}_{1}x_{1})^{2} + (y_{2} - \hat{\beta}_{0} - \hat{\beta}_{1}x_{2})^{2} + \ldots + (y_{n} - \hat{\beta}_{0} - \hat{\beta}_{1}x_{n})^{2}$$</span>
<span id="cb1-78"><a href="#cb1-78"></a></span>
<span id="cb1-79"><a href="#cb1-79"></a>Least squares approachs chooses $\hat{\beta}_{0}$ and $\hat{\beta}_{1}$ to minimize $RSS$:</span>
<span id="cb1-80"><a href="#cb1-80"></a></span>
<span id="cb1-81"><a href="#cb1-81"></a>$$\hat{\beta}_{1} = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}$$</span>
<span id="cb1-82"><a href="#cb1-82"></a></span>
<span id="cb1-83"><a href="#cb1-83"></a>$$\hat{\beta}_{0} = \bar{y} - \hat{\beta}_{1}\bar{x}$$</span>
<span id="cb1-84"><a href="#cb1-84"></a></span>
<span id="cb1-85"><a href="#cb1-85"></a><span class="ss">- </span>$\bar{x}$, $\bar{y}$ = sample means of $x$ and $y$</span>
<span id="cb1-86"><a href="#cb1-86"></a></span>
<span id="cb1-87"><a href="#cb1-87"></a><span class="fu">### Visualization of Fit</span></span>
<span id="cb1-88"><a href="#cb1-88"></a></span>
<span id="cb1-91"><a href="#cb1-91"></a><span class="in">```{r}</span></span>
<span id="cb1-92"><a href="#cb1-92"></a><span class="co">#| label: fig3-2</span></span>
<span id="cb1-93"><a href="#cb1-93"></a><span class="co">#| echo: false</span></span>
<span id="cb1-94"><a href="#cb1-94"></a><span class="co">#| fig-cap: Contour and three-dimensional plots of the RSS on the `Advertising` data, using `sales` as the response and `TV` as the predictor. The red dots correspond to the least squares estimates $\hat{\beta}_{0}$ and $\hat{\beta}_{1}$, given by (3.4).</span></span>
<span id="cb1-95"><a href="#cb1-95"></a><span class="co">#| out-width: 100%</span></span>
<span id="cb1-96"><a href="#cb1-96"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"images/fig3_2.jpg"</span>)</span>
<span id="cb1-97"><a href="#cb1-97"></a><span class="in">```</span></span>
<span id="cb1-98"><a href="#cb1-98"></a></span>
<span id="cb1-99"><a href="#cb1-99"></a></span>
<span id="cb1-100"><a href="#cb1-100"></a></span>
<span id="cb1-101"><a href="#cb1-101"></a><span class="fu">### Assessing Accuracy of Coefficient Estimates</span></span>
<span id="cb1-102"><a href="#cb1-102"></a>Back to our initial assumption (in another notation w/o "$\approx$"):</span>
<span id="cb1-103"><a href="#cb1-103"></a>$$Y = \beta_{0} + \beta_{1}X + \epsilon$$</span>
<span id="cb1-104"><a href="#cb1-104"></a></span>
<span id="cb1-105"><a href="#cb1-105"></a><span class="ss">- </span>This is called the *population regression line*</span>
<span id="cb1-106"><a href="#cb1-106"></a><span class="ss">    - </span>The best approximation under linearity assumption</span>
<span id="cb1-107"><a href="#cb1-107"></a><span class="ss">- </span>Why do we want to assess accuracy of coefficient estimates?</span>
<span id="cb1-108"><a href="#cb1-108"></a><span class="ss">    - </span>$\hat\beta_0$ defines the **slope** = slope implies some relationship which need to be assessed statistically</span>
<span id="cb1-109"><a href="#cb1-109"></a><span class="ss">- </span>$\epsilon$: irreducible error term</span>
<span id="cb1-110"><a href="#cb1-110"></a><span class="ss">    - </span>**Assumption 1**: $\epsilon \sim N(0,\sigma^2)$</span>
<span id="cb1-111"><a href="#cb1-111"></a><span class="ss">    - </span>**Assumption 2**: $\epsilon$ is independent of $X$</span>
<span id="cb1-112"><a href="#cb1-112"></a><span class="ss">    - </span>It's here for many reasons (mostly due to our limited knoledge about the REAL relationship between $Y$ and $X$)</span>
<span id="cb1-113"><a href="#cb1-113"></a><span class="ss">    - </span>"<span class="co">[</span><span class="ot">All models are wrong, but some are useful</span><span class="co">](https://en.wikipedia.org/wiki/All_models_are_wrong)</span>" - George Box</span>
<span id="cb1-114"><a href="#cb1-114"></a><span class="ss">- </span>Problem:</span>
<span id="cb1-115"><a href="#cb1-115"></a><span class="ss">    - </span>$Y$ is a random variable with population mean $\mu$</span>
<span id="cb1-116"><a href="#cb1-116"></a><span class="ss">    - </span>$\hat{y}$ is a random variable with sample mean $\hat{\mu}$ (estimated using data)</span>
<span id="cb1-117"><a href="#cb1-117"></a><span class="ss">    - </span>**How accurate is the \hat{mu} as an estimate of $\mu$?**</span>
<span id="cb1-118"><a href="#cb1-118"></a><span class="ss">    - </span>This is answered by finding the **standard error** ($SE$) for coefficients</span>
<span id="cb1-119"><a href="#cb1-119"></a></span>
<span id="cb1-120"><a href="#cb1-120"></a><span class="fu">#### Standard error of regression coefficients</span></span>
<span id="cb1-121"><a href="#cb1-121"></a><span class="ss">- </span>Residual standard error (RSE): will be used later to find $SE$</span>
<span id="cb1-122"><a href="#cb1-122"></a></span>
<span id="cb1-123"><a href="#cb1-123"></a>$$\mathrm{RSE} = \sqrt{\frac{\mathrm{RSS}}{n - 2}}$$</span>
<span id="cb1-124"><a href="#cb1-124"></a></span>
<span id="cb1-125"><a href="#cb1-125"></a>where $n$ is the sample size</span>
<span id="cb1-126"><a href="#cb1-126"></a><span class="ss">- </span>Standard error assoicated with $\hat{\beta}_{0}$ and $\hat{\beta}_{1}$:</span>
<span id="cb1-127"><a href="#cb1-127"></a>$$\mathrm{SE}(\hat\beta_0)^2 = \sigma^2 \left[\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2}\right]$$</span>
<span id="cb1-128"><a href="#cb1-128"></a></span>
<span id="cb1-129"><a href="#cb1-129"></a>$$\mathrm{SE}(\hat\beta_1)^2 = \frac{\sigma^2}{\sum_{i=1}^n (x_i - \bar{x})^2}$$</span>
<span id="cb1-130"><a href="#cb1-130"></a></span>
<span id="cb1-131"><a href="#cb1-131"></a></span>
<span id="cb1-132"><a href="#cb1-132"></a><span class="ss">- </span>**95% confidence interval:** </span>
<span id="cb1-133"><a href="#cb1-133"></a><span class="ss">    - </span>a range of values such that with 95% probability, the range will contain the true unknown value of the parameter</span>
<span id="cb1-134"><a href="#cb1-134"></a><span class="ss">    - </span>"95" is just a common number</span>
<span id="cb1-135"><a href="#cb1-135"></a></span>
<span id="cb1-136"><a href="#cb1-136"></a><span class="ss">- </span>The 95% CI limits are formed by:</span>
<span id="cb1-137"><a href="#cb1-137"></a></span>
<span id="cb1-138"><a href="#cb1-138"></a>$$\hat\beta_1 \pm 2\ \cdot \ \mathrm{SE}(\hat\beta_1)$$</span>
<span id="cb1-139"><a href="#cb1-139"></a></span>
<span id="cb1-140"><a href="#cb1-140"></a>$$\hat\beta_0 \pm 2\ \cdot \ \mathrm{SE}(\hat\beta_0)$$</span>
<span id="cb1-141"><a href="#cb1-141"></a></span>
<span id="cb1-142"><a href="#cb1-142"></a></span>
<span id="cb1-143"><a href="#cb1-143"></a><span class="ss">- </span>Figure below can be read: "*there's approximately 95% chance that the shaded area will contain the true value of $\beta$*"</span>
<span id="cb1-144"><a href="#cb1-144"></a></span>
<span id="cb1-145"><a href="#cb1-145"></a><span class="al">![Source: https://mathblog.com/statistics/definitions/confidence-interval/95-ci/](images/03-95-percent-confidence-interval.jpg)</span></span>
<span id="cb1-146"><a href="#cb1-146"></a></span>
<span id="cb1-147"><a href="#cb1-147"></a><span class="fu">#### Using SE in hypothesis testing</span></span>
<span id="cb1-148"><a href="#cb1-148"></a><span class="ss">- </span>For any estimated coefficient $\hat{\beta}$:</span>
<span id="cb1-149"><a href="#cb1-149"></a><span class="ss">    1. </span>Formulate a null hypothesis $H_0$ vs. alternative hypothesis $H_a$ about $\hat{\beta}$</span>
<span id="cb1-150"><a href="#cb1-150"></a><span class="ss">    2. </span>Estimate $SE$ </span>
<span id="cb1-151"><a href="#cb1-151"></a><span class="ss">    3. </span>Compute *t-statistic*: $$t = \frac{\hat{\beta}}{SE(\hat{\beta})}$$</span>
<span id="cb1-152"><a href="#cb1-152"></a><span class="ss">    4. </span>Use t-statistic to find the p-value = $Pr(|t|)$</span>
<span id="cb1-153"><a href="#cb1-153"></a><span class="ss">    5. </span>p-value is used to decide whether we reject null hypothesis or not</span>
<span id="cb1-154"><a href="#cb1-154"></a><span class="ss">- </span>$H_0$  is rejected if p-value &lt; $\alpha$</span>
<span id="cb1-155"><a href="#cb1-155"></a><span class="ss">    - </span>$\alpha$ significance level: the common choice is 0.05, but this cutoff vary based on context</span>
<span id="cb1-156"><a href="#cb1-156"></a><span class="ss">    - </span>if the p-value of some coefficient &lt; $\alpha$, then we say it has **significant** effect on $Y$</span>
<span id="cb1-157"><a href="#cb1-157"></a><span class="ss">    - </span>otherwise, we say it has **insignificant** effect on $Y$</span>
<span id="cb1-158"><a href="#cb1-158"></a></span>
<span id="cb1-159"><a href="#cb1-159"></a><span class="al">![Table 3.1](images/03-table3_1.png)</span></span>
<span id="cb1-160"><a href="#cb1-160"></a></span>
<span id="cb1-161"><a href="#cb1-161"></a><span class="ss">- </span>e.g. $H_0$ : There is no relationship between ad. on TV and the increase in sales </span>
<span id="cb1-162"><a href="#cb1-162"></a><span class="ss">    - </span>$\rightarrow$ slope is approximately 0 </span>
<span id="cb1-163"><a href="#cb1-163"></a><span class="ss">    - </span>$\rightarrow$ $H_0$: $\beta_1$ = 0</span>
<span id="cb1-164"><a href="#cb1-164"></a></span>
<span id="cb1-165"><a href="#cb1-165"></a><span class="ss">- </span>Easy to do using Python or R</span>
<span id="cb1-166"><a href="#cb1-166"></a><span class="ss">- </span>More details in chapter 13</span>
<span id="cb1-167"><a href="#cb1-167"></a></span>
<span id="cb1-168"><a href="#cb1-168"></a></span>
<span id="cb1-169"><a href="#cb1-169"></a><span class="fu">### Assessing the Accuracy of the Model</span></span>
<span id="cb1-170"><a href="#cb1-170"></a><span class="at">&gt; i.e. Model Evaluation</span></span>
<span id="cb1-171"><a href="#cb1-171"></a></span>
<span id="cb1-172"><a href="#cb1-172"></a></span>
<span id="cb1-173"><a href="#cb1-173"></a><span class="ss">- </span>Accuracy of the model = Quality of a linear regression fit</span>
<span id="cb1-174"><a href="#cb1-174"></a><span class="ss">- </span>There are four quantities for that:</span>
<span id="cb1-175"><a href="#cb1-175"></a><span class="ss">    1. </span>**Residual standard error** ($RSE$)</span>
<span id="cb1-176"><a href="#cb1-176"></a><span class="ss">    2. </span>$R^2$ **statistic** </span>
<span id="cb1-177"><a href="#cb1-177"></a><span class="ss">    3. </span>Pearson correlation coefficient ($r=Cor(X,Y)$)</span>
<span id="cb1-178"><a href="#cb1-178"></a><span class="ss">    4. </span>$F$-**statistic** (discussed in next section)</span>
<span id="cb1-179"><a href="#cb1-179"></a></span>
<span id="cb1-180"><a href="#cb1-180"></a><span class="ss">- </span>**RSE**: </span>
<span id="cb1-181"><a href="#cb1-181"></a>$$\mathrm{RSE} = \sqrt{\frac{\mathrm{RSS}}{n - 2}}$$</span>
<span id="cb1-182"><a href="#cb1-182"></a><span class="ss">    - </span>**Interpretation:** *absolute measure of the lack of fit of the model*</span>
<span id="cb1-183"><a href="#cb1-183"></a><span class="ss">    - </span>**small value** = model fits the data well</span>
<span id="cb1-184"><a href="#cb1-184"></a><span class="ss">    - </span>measured in the unit of $Y$ (e.g. RSE = 3.2 units sold)</span>
<span id="cb1-185"><a href="#cb1-185"></a><span class="ss">- </span>*$R^2$* statistic (a.k.a coefficient of determination): </span>
<span id="cb1-186"><a href="#cb1-186"></a>$$R^2 = 1 - \frac{RSS}{TSS}$$</span>
<span id="cb1-187"><a href="#cb1-187"></a>where TSS is the **total sum of squares**:</span>
<span id="cb1-188"><a href="#cb1-188"></a>$$TSS = \Sigma (y_i - \bar{y})^2$$</span>
<span id="cb1-189"><a href="#cb1-189"></a><span class="ss">    - </span>**Interpretation:** *proportion of the variance in $Y$ explained by using some predictor $X$* </span>
<span id="cb1-190"><a href="#cb1-190"></a><span class="ss">    - </span>a *good value* depends on the application.</span>
<span id="cb1-191"><a href="#cb1-191"></a><span class="ss">    - </span>ranges from 0 to 1 (<span class="co">[</span><span class="ot">can be negative in extreme cases?</span><span class="co">](https://www.graphpad.com/support/faq/how-can-rsup2sup-be-negative/)</span>)</span>
<span id="cb1-192"><a href="#cb1-192"></a></span>
<span id="cb1-193"><a href="#cb1-193"></a><span class="ss">- </span>Pearson correlation coefficient ($r=Cor(X,Y)$)</span>
<span id="cb1-194"><a href="#cb1-194"></a>$$r = Cor(X,Y) = \frac{\sum{(x_i - \bar{x})(y_i - \bar{y})}}{\sqrt{\sum{(x_i - \bar{x})^2} \sum{(y_i - \bar{y})^2}}}$$</span>
<span id="cb1-195"><a href="#cb1-195"></a><span class="ss">    - </span>$R^2=r^2$ in simple linear regression</span>
<span id="cb1-196"><a href="#cb1-196"></a></span>
<span id="cb1-197"><a href="#cb1-197"></a></span>
<span id="cb1-198"><a href="#cb1-198"></a><span class="fu">## Multiple Linear Regression</span></span>
<span id="cb1-199"><a href="#cb1-199"></a></span>
<span id="cb1-200"><a href="#cb1-200"></a><span class="fu">### Definition</span></span>
<span id="cb1-201"><a href="#cb1-201"></a></span>
<span id="cb1-202"><a href="#cb1-202"></a>**Multiple linear regression** extends simple linear regression for *p* predictors:</span>
<span id="cb1-203"><a href="#cb1-203"></a></span>
<span id="cb1-204"><a href="#cb1-204"></a>$$Y = \beta_{0} + \beta_{1}X_1 + \beta_{2}X_2 + ... +\beta_{p}X_p + \epsilon_i$$</span>
<span id="cb1-205"><a href="#cb1-205"></a></span>
<span id="cb1-206"><a href="#cb1-206"></a><span class="ss">- </span>$\beta_{j}$ is the *average* effect on $Y$ from $X_{j}$ holding all other predictors fixed.</span>
<span id="cb1-207"><a href="#cb1-207"></a><span class="ss">    - </span>But this is not the case in reality! (e.g. using weight and height as predictors in some model)</span>
<span id="cb1-208"><a href="#cb1-208"></a><span class="ss">- </span>For $p=2$ predictors, the model represents a plane in the 3D space instead of a line</span>
<span id="cb1-209"><a href="#cb1-209"></a><span class="al">![Figure 3.4 in ISLP](images\03-fig3_4.png)</span></span>
<span id="cb1-210"><a href="#cb1-210"></a>$$\hat{y} = \hat{\beta_{0}} + \hat{\beta_{1}}x_1 + \hat{\beta_{2}}x_2 + ... + \hat{\beta_{p}}x_p$$</span>
<span id="cb1-211"><a href="#cb1-211"></a></span>
<span id="cb1-212"><a href="#cb1-212"></a><span class="ss">- </span>As in the simple case, we aim to choose the set of coefficients $\hat{\beta_{0}}, \hat{\beta_{1}}, ..., \hat{\beta_{p}}$ that minimizes the $RSS$ when making predictions using $\hat{y}$</span>
<span id="cb1-213"><a href="#cb1-213"></a></span>
<span id="cb1-214"><a href="#cb1-214"></a><span class="ss">- </span>In this section, we assume predictors are **independent** of each others</span>
<span id="cb1-215"><a href="#cb1-215"></a></span>
<span id="cb1-216"><a href="#cb1-216"></a><span class="ss">- </span>Important notes (<span class="co">[</span><span class="ot">from lecture 3</span><span class="co">](https://www.youtube.com/watch?v=o9hoLdylWKo&amp;list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ&amp;index=15)</span>)</span>
<span id="cb1-217"><a href="#cb1-217"></a><span class="ss">    - </span>Ideal scenario (i.e. balanced design): Predictors are uncorrelated</span>
<span id="cb1-218"><a href="#cb1-218"></a><span class="ss">    - </span>Correlations amongst predictors cause problems</span>
<span id="cb1-219"><a href="#cb1-219"></a><span class="ss">        - </span>When a change on some predictor $X_j$ changes everything else, coefficient intepretations become hazardous</span>
<span id="cb1-220"><a href="#cb1-220"></a><span class="ss">        - </span>Makes thing complicated when discussing **causality**</span>
<span id="cb1-221"><a href="#cb1-221"></a>    </span>
<span id="cb1-222"><a href="#cb1-222"></a></span>
<span id="cb1-223"><a href="#cb1-223"></a><span class="fu">### Important Questions in MLR</span></span>
<span id="cb1-224"><a href="#cb1-224"></a></span>
<span id="cb1-225"><a href="#cb1-225"></a><span class="at">&gt; More variables/predictors $\rightarrow$ More things to assess!</span></span>
<span id="cb1-226"><a href="#cb1-226"></a></span>
<span id="cb1-227"><a href="#cb1-227"></a><span class="ss">1. </span>**Relationship between the resposne and predictors:** *Is at least one of the predictors $X_1$, $X_2$,  ... , $X_p$ useful in predicting the response?*</span>
<span id="cb1-228"><a href="#cb1-228"></a>    a. formulate a null hypothesis $H_0: \beta_1 = \beta_2 = ... = \beta_p = 0$ </span>
<span id="cb1-229"><a href="#cb1-229"></a>    b. compute $F$-statistic $$F = \frac{(TSS-RSS)/p}{RSS/(n-p-1)}$$ </span>
<span id="cb1-230"><a href="#cb1-230"></a>    c. use it to find p-value (all of that can be don using computers)</span>
<span id="cb1-231"><a href="#cb1-231"></a></span>
<span id="cb1-232"><a href="#cb1-232"></a></span>
<span id="cb1-233"><a href="#cb1-233"></a></span>
<span id="cb1-234"><a href="#cb1-234"></a></span>
<span id="cb1-235"><a href="#cb1-235"></a><span class="ss">2. </span>**Deciding on important variables to include in the model:** *Do all the predictors help to explain $Y$ , or is only a subset of the predictors useful?*</span>
<span id="cb1-236"><a href="#cb1-236"></a></span>
<span id="cb1-237"><a href="#cb1-237"></a><span class="ss">    - </span>a.k.a. Model Selection Problem</span>
<span id="cb1-238"><a href="#cb1-238"></a><span class="ss">    - </span>**Option 1**: test all possibilities and choose the best subset (inefficient with many variables w/ $2^p$ possible models)</span>
<span id="cb1-239"><a href="#cb1-239"></a><span class="ss">    - </span>**Option 2**: use a **variable selection** algorithm (Forward - Backward - Mixed)</span>
<span id="cb1-240"><a href="#cb1-240"></a><span class="ss">        - </span>Discussed in detail in Chapter 6</span>
<span id="cb1-241"><a href="#cb1-241"></a></span>
<span id="cb1-242"><a href="#cb1-242"></a><span class="ss">3. </span>**Model evaluation:** *How well does the model fit the data?*</span>
<span id="cb1-243"><a href="#cb1-243"></a></span>
<span id="cb1-244"><a href="#cb1-244"></a><span class="ss">    - </span>**$R^2$** still gives *proportion of the variance explained*</span>
<span id="cb1-245"><a href="#cb1-245"></a><span class="ss">        - </span>Adding predictors w/ no association to $Y$ can reducde $R^2$ but results in overfitting</span>
<span id="cb1-246"><a href="#cb1-246"></a><span class="ss">    - </span>Can also look at **RSE** which is generalized for multiple regression as: $$RSE = \sqrt{\frac{1}{n-p-1}RSS}$$</span>
<span id="cb1-247"><a href="#cb1-247"></a></span>
<span id="cb1-248"><a href="#cb1-248"></a><span class="ss">4. </span>**Making and assising predictions:** *Given a set of predictor values, what response value should we predict,</span>
<span id="cb1-249"><a href="#cb1-249"></a>and how accurate is our prediction?* </span>
<span id="cb1-250"><a href="#cb1-250"></a></span>
<span id="cb1-251"><a href="#cb1-251"></a>    Three sets of uncertainty in predictions:</span>
<span id="cb1-252"><a href="#cb1-252"></a>    </span>
<span id="cb1-253"><a href="#cb1-253"></a><span class="ss">    - </span>Uncertainty in $\hat{\beta_i}$ the estimates of $\beta_i$ (use **confidence interval**)</span>
<span id="cb1-254"><a href="#cb1-254"></a><span class="ss">    - </span>Model bias (i.e. inductive bias): casued by our assumptions</span>
<span id="cb1-255"><a href="#cb1-255"></a><span class="ss">    - </span>Irreducible error $\epsilon$ (use **prediction interval**): even if we know the true $\beta_i$, there is still $\epsilon$!</span>
<span id="cb1-256"><a href="#cb1-256"></a><span class="ss">        - </span>PI is wider than CI because it incorporates all all kinds of errors.</span>
<span id="cb1-257"><a href="#cb1-257"></a></span>
<span id="cb1-258"><a href="#cb1-258"></a><span class="fu">## Qualitative Predictors</span></span>
<span id="cb1-259"><a href="#cb1-259"></a><span class="at">&gt; a.k.a. *categorical predictors* or *factor variables*</span></span>
<span id="cb1-260"><a href="#cb1-260"></a></span>
<span id="cb1-261"><a href="#cb1-261"></a><span class="ss">- </span>**Dummy variables** (a.k.a. one-hot encoding): if there are $k$ levels, introduce $k-1$ dummy variables which are equal to one when the underlying qualitative predictor takes that value. </span>
<span id="cb1-262"><a href="#cb1-262"></a><span class="ss">- </span>For example if there are 3 levels, introduce 2 new dummy variables ($x_1$ and $x_2$) and fit the model:</span>
<span id="cb1-263"><a href="#cb1-263"></a></span>
<span id="cb1-264"><a href="#cb1-264"></a>$$y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \epsilon_i$$</span>
<span id="cb1-265"><a href="#cb1-265"></a></span>
<span id="cb1-266"><a href="#cb1-266"></a>| Qualitative Predicitor | $x_{i1}$ | $x_{i2}$ |</span>
<span id="cb1-267"><a href="#cb1-267"></a>| ---------------------- |:--------:|:--------:|</span>
<span id="cb1-268"><a href="#cb1-268"></a>| level 0    (baseline)  |    0     |    0     |</span>
<span id="cb1-269"><a href="#cb1-269"></a>| level 1                |    1     |    0     |</span>
<span id="cb1-270"><a href="#cb1-270"></a>| level 2                |    0     |    1     |</span>
<span id="cb1-271"><a href="#cb1-271"></a></span>
<span id="cb1-272"><a href="#cb1-272"></a><span class="ss">- </span>Coefficients are interpreted the average effect relative to the baseline.</span>
<span id="cb1-273"><a href="#cb1-273"></a></span>
<span id="cb1-274"><a href="#cb1-274"></a></span>
<span id="cb1-275"><a href="#cb1-275"></a><span class="fu">## Extensions to the Linear Model</span></span>
<span id="cb1-276"><a href="#cb1-276"></a></span>
<span id="cb1-277"><a href="#cb1-277"></a><span class="ss">- </span>**Interaction/Synergy Effects**  </span>
<span id="cb1-278"><a href="#cb1-278"></a><span class="ss">    - </span>Remove the previous assumptions about independence among predictors (additive assumption)</span>
<span id="cb1-279"><a href="#cb1-279"></a></span>
<span id="cb1-280"><a href="#cb1-280"></a><span class="ss">    - </span>Add a product term $X_1 \times X_2$ with its own coefficient $\beta_3$ to model how the relationship between $Y$ and one variable $X_1$ changes depending on the value of the other variable $X_2$:  $$Y = \beta_{0} + \beta_{1}X_1 + \beta_{2}X_2 + \beta_{3}(X_1 \cdot X_2) + \epsilon_i$$</span>
<span id="cb1-281"><a href="#cb1-281"></a><span class="ss">        - </span>There are many possibilities (e.g. interaction between quant. and qualit. variables)</span>
<span id="cb1-282"><a href="#cb1-282"></a><span class="ss">- </span>Non-linear relationships (e.g. polynomial fits)</span>
<span id="cb1-283"><a href="#cb1-283"></a> </span>
<span id="cb1-284"><a href="#cb1-284"></a>$$Y = \beta_{0} + \beta_{1}X + \beta_{2}X^2 + ... \beta_{n}X^n + \epsilon_i$$</span>
<span id="cb1-285"><a href="#cb1-285"></a></span>
<span id="cb1-286"><a href="#cb1-286"></a><span class="fu">## Potential Problems</span></span>
<span id="cb1-287"><a href="#cb1-287"></a><span class="at">&gt; Common problems with linear models and tips to address them</span></span>
<span id="cb1-288"><a href="#cb1-288"></a></span>
<span id="cb1-289"><a href="#cb1-289"></a><span class="ss">1. </span>*Non-linear relationships* </span>
<span id="cb1-290"><a href="#cb1-290"></a><span class="al">![Figure 3.9](images/03-fig3_9.png)</span></span>
<span id="cb1-291"><a href="#cb1-291"></a><span class="ss">    - </span>Residual plots are useful tool to see if any remaining trends exist. </span>
<span id="cb1-292"><a href="#cb1-292"></a><span class="ss">    - </span>If a non-linear associations are observed, consider transformaing predictors before fitting (e.g. $log X$)</span>
<span id="cb1-293"><a href="#cb1-293"></a>    </span>
<span id="cb1-294"><a href="#cb1-294"></a><span class="ss">2. </span>*Correlation of Error Terms*</span>
<span id="cb1-295"><a href="#cb1-295"></a></span>
<span id="cb1-296"><a href="#cb1-296"></a>    Linear regression assumes that the error terms $\epsilon_i$ are uncorrelated. Residuals may indicate that this is not correct (obvious *tracking* in the data). One could also look at the autocorrelation of the residuals (e.g. time-series). </span>
<span id="cb1-297"><a href="#cb1-297"></a>    </span>
<span id="cb1-298"><a href="#cb1-298"></a><span class="ss">3. </span>*Non-constant variance of error terms*</span>
<span id="cb1-299"><a href="#cb1-299"></a></span>
<span id="cb1-300"><a href="#cb1-300"></a>    Again this can be revealed by examining the residuals.  Consider transformation of the predictors to remove non-constant variance. The figure below shows residuals demonstrating non-constant variance, and shows this being mitigated to a great extent by log transforming the data.</span>
<span id="cb1-301"><a href="#cb1-301"></a></span>
<span id="cb1-304"><a href="#cb1-304"></a><span class="in">```{r}</span></span>
<span id="cb1-305"><a href="#cb1-305"></a><span class="co">#| label: fig3-11</span></span>
<span id="cb1-306"><a href="#cb1-306"></a><span class="co">#| echo: false</span></span>
<span id="cb1-307"><a href="#cb1-307"></a><span class="co">#| fig-cap: Figure 3.11</span></span>
<span id="cb1-308"><a href="#cb1-308"></a><span class="co">#| out-width: 100%</span></span>
<span id="cb1-309"><a href="#cb1-309"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"images/fig3_11.png"</span>)</span>
<span id="cb1-310"><a href="#cb1-310"></a><span class="in">```</span></span>
<span id="cb1-311"><a href="#cb1-311"></a></span>
<span id="cb1-312"><a href="#cb1-312"></a><span class="ss">4. </span>*Outliers*</span>
<span id="cb1-313"><a href="#cb1-313"></a></span>
<span id="cb1-314"><a href="#cb1-314"></a><span class="ss">    - </span>Observations for which $y_i$ is unusual given $x_i$ (see point '20' in figure 3.12)</span>
<span id="cb1-315"><a href="#cb1-315"></a><span class="ss">    - </span>Often outliers are mistakes in data collection and can be removed, but could also be an indicator of a deficient model.  </span>
<span id="cb1-316"><a href="#cb1-316"></a><span class="ss">    - </span>Detect outliers by plotting studentized residuals (residual $e_i$ divided by the estimated error) and look for residuals larger then 3 standard deviations in absolute value.</span>
<span id="cb1-317"><a href="#cb1-317"></a><span class="ss">    - </span>An outlier may not effect the fit much but can have dramatic effect on the **RSE**. </span>
<span id="cb1-318"><a href="#cb1-318"></a><span class="ss">    - </span>We need to identify these before fitting the model</span>
<span id="cb1-319"><a href="#cb1-319"></a></span>
<span id="cb1-320"><a href="#cb1-320"></a><span class="al">![Figure 3.12](images/03-fig3_12.png)</span></span>
<span id="cb1-321"><a href="#cb1-321"></a></span>
<span id="cb1-322"><a href="#cb1-322"></a></span>
<span id="cb1-323"><a href="#cb1-323"></a></span>
<span id="cb1-324"><a href="#cb1-324"></a><span class="ss">5. </span>*High Leverage Points* </span>
<span id="cb1-325"><a href="#cb1-325"></a></span>
<span id="cb1-326"><a href="#cb1-326"></a><span class="ss">    - </span>These are points with unusual values of $x_i$ (see point '41' in figure 3.13)</span>
<span id="cb1-327"><a href="#cb1-327"></a><span class="ss">    - </span>These points can have large impact on the fit, as in the example, including point 41 pulls slope up significantly.</span>
<span id="cb1-328"><a href="#cb1-328"></a><span class="ss">    - </span>Use *leverage statistic* to identify high leverage points before fitting the model, which can be hard to identify in multiple regression.</span>
<span id="cb1-329"><a href="#cb1-329"></a></span>
<span id="cb1-332"><a href="#cb1-332"></a><span class="in">```{r}</span></span>
<span id="cb1-333"><a href="#cb1-333"></a><span class="co">#| label: fig3-13</span></span>
<span id="cb1-334"><a href="#cb1-334"></a><span class="co">#| echo: false</span></span>
<span id="cb1-335"><a href="#cb1-335"></a><span class="co">#| fig-cap: Figure 3.13</span></span>
<span id="cb1-336"><a href="#cb1-336"></a><span class="co">#| out-width: 100%</span></span>
<span id="cb1-337"><a href="#cb1-337"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"images/fig3_13.png"</span>)</span>
<span id="cb1-338"><a href="#cb1-338"></a><span class="in">```</span></span>
<span id="cb1-339"><a href="#cb1-339"></a></span>
<span id="cb1-340"><a href="#cb1-340"></a><span class="ss">6. </span>*Collinearity*</span>
<span id="cb1-341"><a href="#cb1-341"></a></span>
<span id="cb1-342"><a href="#cb1-342"></a><span class="ss">    - </span>Two predictor variables are closely related to one another.</span>
<span id="cb1-343"><a href="#cb1-343"></a>    </span>
<span id="cb1-344"><a href="#cb1-344"></a><span class="ss">    - </span>The problem is that it's difficult to separate out the individual effect of each one on the reponse.</span>
<span id="cb1-345"><a href="#cb1-345"></a><span class="ss">    - </span>Often can be addressed with by: </span>
<span id="cb1-346"><a href="#cb1-346"></a><span class="ss">        1. </span>Dropping one of the highly correlated predictors or </span>
<span id="cb1-347"><a href="#cb1-347"></a><span class="ss">        2. </span>Combining correlated predictors into one variable. </span>
<span id="cb1-348"><a href="#cb1-348"></a></span>
<span id="cb1-349"><a href="#cb1-349"></a><span class="ss">    - </span>*Multicollinearity* (collinearity involving 3 or more predictors) is not so easy to identify. </span>
<span id="cb1-350"><a href="#cb1-350"></a><span class="ss">        - </span>Use *Variance inflation factor*, which is the ratio of the variance of $\hat{\beta_j}$ when fitting the full model to fitting the parameter on its own. Can be computed using the formula: $$VIF(\hat{\beta_j}) = \frac{1}{1-R^2_{X_j|X_{-j}}}$$</span>
<span id="cb1-351"><a href="#cb1-351"></a>        </span>
<span id="cb1-352"><a href="#cb1-352"></a><span class="ss">            - </span>where $R^2_{X_j|X_{-j}}$ is the $R^2$ from a regression of $X_j$ onto all the other predictors.</span>
<span id="cb1-353"><a href="#cb1-353"></a><span class="ss">            - </span>large $VIF$ indicates the presence of collinearty</span>
<span id="cb1-354"><a href="#cb1-354"></a></span>
<span id="cb1-355"><a href="#cb1-355"></a><span class="fu">## Answers to the Marketing Plan questions</span></span>
<span id="cb1-356"><a href="#cb1-356"></a></span>
<span id="cb1-357"><a href="#cb1-357"></a><span class="ss">1. </span>**Is there a relationship between advertising budget and sales?**</span>
<span id="cb1-358"><a href="#cb1-358"></a></span>
<span id="cb1-359"><a href="#cb1-359"></a>    Tool: Multiple regression, look at F-statistic.</span>
<span id="cb1-360"><a href="#cb1-360"></a></span>
<span id="cb1-361"><a href="#cb1-361"></a><span class="ss">2. </span>**How strong is the relationship between advertising budget and sales?** </span>
<span id="cb1-362"><a href="#cb1-362"></a></span>
<span id="cb1-363"><a href="#cb1-363"></a>    Tool: **$R^2$** and **RSE**</span>
<span id="cb1-364"><a href="#cb1-364"></a>    </span>
<span id="cb1-365"><a href="#cb1-365"></a><span class="ss">3. </span>**Which media are associated with sales?**</span>
<span id="cb1-366"><a href="#cb1-366"></a> </span>
<span id="cb1-367"><a href="#cb1-367"></a>    Tool: model selection approaches e.g. p-values for each predictor's *t-statistic*.  Explored further in chapter 6.</span>
<span id="cb1-368"><a href="#cb1-368"></a></span>
<span id="cb1-369"><a href="#cb1-369"></a><span class="ss">4. </span>**How large is the association between each medium and sales?**</span>
<span id="cb1-370"><a href="#cb1-370"></a></span>
<span id="cb1-371"><a href="#cb1-371"></a>    Tool: Confidence intervals on $\hat{\beta_j}$. Narrow CI is a strong evidence for association</span>
<span id="cb1-372"><a href="#cb1-372"></a></span>
<span id="cb1-373"><a href="#cb1-373"></a><span class="ss">5. </span>**How accurately can we predict future sales?**</span>
<span id="cb1-374"><a href="#cb1-374"></a></span>
<span id="cb1-375"><a href="#cb1-375"></a>    Tool: Prediction intervals for individual response, confidence intervals for average response.</span>
<span id="cb1-376"><a href="#cb1-376"></a>    </span>
<span id="cb1-377"><a href="#cb1-377"></a>    </span>
<span id="cb1-378"><a href="#cb1-378"></a><span class="ss">6. </span>**Is the relationship linear?** </span>
<span id="cb1-379"><a href="#cb1-379"></a></span>
<span id="cb1-380"><a href="#cb1-380"></a>    Tool: Residual Plots</span>
<span id="cb1-381"><a href="#cb1-381"></a>    </span>
<span id="cb1-382"><a href="#cb1-382"></a><span class="ss">7. </span>**Is there synergy among the advertising media?** </span>
<span id="cb1-383"><a href="#cb1-383"></a></span>
<span id="cb1-384"><a href="#cb1-384"></a>    Tool: Interaction terms and the significance of interaction term's coefficient.</span>
<span id="cb1-385"><a href="#cb1-385"></a></span>
<span id="cb1-386"><a href="#cb1-386"></a><span class="fu">## Comparison of Linear Regression with K-Nearest Neighbors</span></span>
<span id="cb1-387"><a href="#cb1-387"></a></span>
<span id="cb1-388"><a href="#cb1-388"></a><span class="ss">- </span>This section examines the K-nearest neighbor (KNN) method (a non-parameteric method).</span>
<span id="cb1-389"><a href="#cb1-389"></a><span class="ss">- </span>Non-parametric methods doesn't make assumptions about the form of $f(X)$ (e.g. linearity)</span>
<span id="cb1-390"><a href="#cb1-390"></a><span class="ss">- </span>This is essentially a $K$-point moving average.</span>
<span id="cb1-391"><a href="#cb1-391"></a></span>
<span id="cb1-392"><a href="#cb1-392"></a><span class="al">![](images/03-fig3_16.png)</span></span>
<span id="cb1-393"><a href="#cb1-393"></a></span>
<span id="cb1-394"><a href="#cb1-394"></a><span class="ss">- </span>$K$ determines the model smoothness </span>
<span id="cb1-395"><a href="#cb1-395"></a><span class="ss">    - </span>Small value: low bias &amp; high variance</span>
<span id="cb1-396"><a href="#cb1-396"></a><span class="ss">    - </span>High value: high bias &amp; low variance</span>
<span id="cb1-397"><a href="#cb1-397"></a><span class="ss">- </span>This serves to illustrate the Bias-Variance trade-off nicely.</span>
<span id="cb1-398"><a href="#cb1-398"></a><span class="ss">- </span>However, parameteric methods outperform non-parameteric methods if the assumptions made were close to the true $f(X)$.</span>
<span id="cb1-399"><a href="#cb1-399"></a></span>
<span id="cb1-400"><a href="#cb1-400"></a></span>
<span id="cb1-401"><a href="#cb1-401"></a></span>
<span id="cb1-402"><a href="#cb1-402"></a><span class="fu">## Helpful links</span></span>
<span id="cb1-403"><a href="#cb1-403"></a><span class="ss">- </span><span class="co">[</span><span class="ot">https://mlu-explain.github.io/linear-regression/</span><span class="co">](https://mlu-explain.github.io/linear-regression/)</span></span>
<span id="cb1-404"><a href="#cb1-404"></a><span class="ss">- </span><span class="co">[</span><span class="ot">https://observablehq.com/@yizhe-ang/interactive-visualization-of-linear-regression</span><span class="co">](https://observablehq.com/@yizhe-ang/interactive-visualization-of-linear-regression)</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>