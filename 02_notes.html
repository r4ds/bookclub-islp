<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Notes â€“ Introduction to Statistical Learning using Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./02_video.html" rel="next">
<link href="./02_main.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-707d8167ce6003fca903bfe2be84ab7f.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-0204ecbfb8a16f1d6bd85439096a7cdd.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-0204ecbfb8a16f1d6bd85439096a7cdd.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-0204ecbfb8a16f1d6bd85439096a7cdd.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="module">
  // When keyboard's 's' key is pressed, 
  // hide both sidebars (tables of contents)
  document.addEventListener(
    "keydown", 
    function (evt) {
      // Avoid keydown event repetition due to holding key
      if (evt.repeat) return;

      if ('s' === event.key.toLowerCase()) {
        const quartoContent = document.querySelector("#quarto-content");
        
        if (window.getComputedStyle(quartoContent).display === 'grid') {
          // Remove grid display
          quartoContent.style.display = "block";
          
          // Hide every HTML element, except for main content
          quartoContent
            .querySelectorAll(":scope > :not(.content, script)")
            .forEach(e => e.style.display = "none");
  
          // Change content margin for desktop view
          quartoContent
            .querySelector("main.content")
            .style.margin = "20px 100px";
        } else {
          // Try to restore Quarto's initial style
          quartoContent.style.display = "grid";

          quartoContent
            .querySelectorAll(":scope > :not(.content, script)")
            .forEach(e => e.style.display = "flex");

          quartoContent
            .querySelector("main.content")
            .style.margin = "21px 0";
        }
      }
    }
  );
</script> 

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02_main.html">2. Statistical Learning</a></li><li class="breadcrumb-item"><a href="./02_notes.html">Notes</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Statistical Learning using Python</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/r4ds/bookclub-islp" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./01_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. Introduction</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./02_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Statistical Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_notes.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Applied Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./03_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Linear Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./04_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Classification</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./05_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Resampling Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./06_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Linear Model Selection and Regularization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./07_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Moving Beyond Linearity</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./08_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. Tree-Based Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./09_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. Support Vector Machines</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./10_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./11_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Survival Analysis and Censored Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./12_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12. Unsupervised Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./13_main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13. Multiple Testing</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_video.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Video</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Examples</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example_quarto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Example Quarto Document</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./example_python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">NumPy</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./how-to.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to add to the book</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-is-statistical-learning" id="toc-what-is-statistical-learning" class="nav-link active" data-scroll-target="#what-is-statistical-learning">What is Statistical Learning?</a>
  <ul class="collapse">
  <li><a href="#why-estimate-f" id="toc-why-estimate-f" class="nav-link" data-scroll-target="#why-estimate-f">Why estimate <span class="math inline">\(f\)</span>?</a></li>
  <li><a href="#how-do-we-estimate-f" id="toc-how-do-we-estimate-f" class="nav-link" data-scroll-target="#how-do-we-estimate-f">How do we estimate <span class="math inline">\(f\)</span> ?</a></li>
  <li><a href="#the-trade-off-between-prediction-accuracy-and-model-interpretability" id="toc-the-trade-off-between-prediction-accuracy-and-model-interpretability" class="nav-link" data-scroll-target="#the-trade-off-between-prediction-accuracy-and-model-interpretability">The trade-off between prediction accuracy and model interpretability</a></li>
  <li><a href="#supervised-vs-unsupervised-learning" id="toc-supervised-vs-unsupervised-learning" class="nav-link" data-scroll-target="#supervised-vs-unsupervised-learning">Supervised vs Unsupervised Learning</a></li>
  <li><a href="#regression-vs-classification-problems" id="toc-regression-vs-classification-problems" class="nav-link" data-scroll-target="#regression-vs-classification-problems">Regression vs Classification problems</a></li>
  </ul></li>
  <li><a href="#assessing-model-accuracy" id="toc-assessing-model-accuracy" class="nav-link" data-scroll-target="#assessing-model-accuracy">Assessing model accuracy</a>
  <ul class="collapse">
  <li><a href="#measuring-the-quality-of-fit" id="toc-measuring-the-quality-of-fit" class="nav-link" data-scroll-target="#measuring-the-quality-of-fit">Measuring the quality of fit</a></li>
  <li><a href="#the-bias-variance-trade-off" id="toc-the-bias-variance-trade-off" class="nav-link" data-scroll-target="#the-bias-variance-trade-off">The Bias-Variance Trade-off</a></li>
  <li><a href="#the-classification-setting" id="toc-the-classification-setting" class="nav-link" data-scroll-target="#the-classification-setting">The Classification setting</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02_main.html">2. Statistical Learning</a></li><li class="breadcrumb-item"><a href="./02_notes.html">Notes</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Notes</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="what-is-statistical-learning" class="level2">
<h2 class="anchored" data-anchor-id="what-is-statistical-learning">What is Statistical Learning?</h2>
<p>In this chapter will deal with developing an <strong>accurate</strong> model that can be used to <strong>predict</strong> some value.</p>
<p>Notation:</p>
<ul>
<li><strong>Input variables</strong>: <span class="math inline">\(X_1, \cdots, X_p\)</span><br>
Also known as <em>predictors, features, independent variables</em>.</li>
<li><strong>Output variable</strong>: <span class="math inline">\(Y\)</span><br>
Also known as <em>response or dependent variable</em>.</li>
</ul>
<p>We assume there is some relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X = \left( X_1, \cdots, X_p \right)\)</span>, which we write as:</p>
<p><span class="math display">\[Y = f(X) + \epsilon\]</span></p>
<p>, where <span class="math inline">\(\epsilon\)</span> is a random <strong>error term</strong> which is <strong>independent</strong> from <span class="math inline">\(X\)</span> and has mean zero; and, <span class="math inline">\(f\)</span> represents the <strong>systematic information</strong> that <span class="math inline">\(X\)</span> provides about <span class="math inline">\(Y\)</span> .</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/02-prediction.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Income data set</figcaption>
</figure>
</div>
</div>
</div>
<p>In essence, statistical learning deals with <strong>different approaches to estimate <span class="math inline">\(f\)</span></strong> .</p>
<section id="why-estimate-f" class="level3">
<h3 class="anchored" data-anchor-id="why-estimate-f">Why estimate <span class="math inline">\(f\)</span>?</h3>
<p>Two main reasons to estimate <span class="math inline">\(f\)</span>:</p>
<section id="prediction" class="level4">
<h4 class="anchored" data-anchor-id="prediction">Prediction</h4>
<ul>
<li><p>Predict <span class="math inline">\(Y\)</span> using a set of inputs <span class="math inline">\(X\)</span> .</p></li>
<li><p>Representation: <span class="math inline">\(\hat{Y}= \hat{f}(X)\)</span>, where <span class="math inline">\(\hat{f}\)</span> represents our <em>estimate</em> for <span class="math inline">\(f\)</span>, and <span class="math inline">\(\hat{Y}\)</span> our <em>prediction</em> for <span class="math inline">\(Y\)</span> .*</p></li>
<li><p>In this setting, <span class="math inline">\(\hat{f}\)</span> is often treated as a <strong>black-box</strong>, meaning we donâ€™t mind not knowing the exact form of <span class="math inline">\(\hat{f}\)</span>, if it generates accurate predictions for <span class="math inline">\(Y\)</span> .</p></li>
<li><p><span class="math inline">\(\hat{Y}\)</span>â€™s accuracy depends on:</p>
<ul>
<li><strong>Reducible error</strong>
<ul>
<li>Due to <span class="math inline">\(\hat{f}\)</span> not being a perfect estimate for <span class="math inline">\(f\)</span>.</li>
<li><strong>Can be reduced</strong> by using a proper statistical learning technique.</li>
</ul></li>
<li><strong>Irreducible error</strong>
<ul>
<li>Due to <span class="math inline">\(\epsilon\)</span> and its variability.</li>
<li><span class="math inline">\(\epsilon\)</span> is independent from <span class="math inline">\(X\)</span>, so no matter how well we estimate <span class="math inline">\(f\)</span>, we canâ€™t reduce this error.</li>
</ul></li>
</ul></li>
<li><p>The quantity <span class="math inline">\(\epsilon\)</span> may contain <strong>unmeasured variables</strong> useful for predicting <span class="math inline">\(Y\)</span>; or, may contain <strong>unmeasure variation</strong>, so no prediction model will be perfect.</p></li>
<li><p>Mathematical form, after choosing predictors <span class="math inline">\(X\)</span> and an estimate <span class="math inline">\(\hat{f}\)</span>:</p></li>
</ul>
<p><span class="math display">\[
E( Y - \hat{Y} )^2 =
E(f(X) + \epsilon - \hat{f}(X))^2 =
\underbrace{[f(X) - \hat{f}(X)]^2}_{reducible} +
\underbrace{\text{ Var}(\epsilon)}_{irreducible}\; .
\]</span></p>
<p>In practice, we almost always donâ€™t know how <span class="math inline">\(\epsilon\)</span>â€™s variability affects our model, so, in this boook, we will focus on techniques for estimating <span class="math inline">\(f\)</span> .</p>
</section>
<section id="inference" class="level4">
<h4 class="anchored" data-anchor-id="inference">Inference</h4>
<p>In this case, we are interested in <strong>understanding the association</strong> between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_1, \cdots, X_p\)</span>.</p>
<ul>
<li>For example:
<ul>
<li><em>Which predictors are most associated with response?</em></li>
<li><em>What is the relationship between the response and each predictor?</em></li>
<li><em>Can such relationship be summarized via a linear equation, or is it more complex?</em></li>
</ul></li>
</ul>
<p>The exact form of <span class="math inline">\(\hat{f}\)</span> is required.</p>
<p>Linear models allow for easier interpretability, but can lack in prediction accuracy; while, non-linear models can be more accurate, but less interpretable.</p>
</section>
</section>
<section id="how-do-we-estimate-f" class="level3">
<h3 class="anchored" data-anchor-id="how-do-we-estimate-f">How do we estimate <span class="math inline">\(f\)</span> ?</h3>
<ul>
<li><p>First, letâ€™s agree on some conventions:</p>
<ul>
<li><span class="math inline">\(n\)</span> : Number of observations.</li>
<li><span class="math inline">\(x_{ij}\)</span>: Value of the <span class="math inline">\(j\text{th}\)</span> predictor, for <span class="math inline">\(i\text{th}\)</span> observation.</li>
<li><span class="math inline">\(y_i\)</span> : Response variable for <span class="math inline">\(i\text{th}\)</span> observation.</li>
<li><strong>Training data</strong>:
<ul>
<li>Set of observations.</li>
<li>Used to esmitate <span class="math inline">\(f\)</span>.</li>
<li><span class="math inline">\(\left\{ (x_1, y_1), \cdots, (x_n, y_n) \right\}\)</span>, where <span class="math inline">\(x_i = (x_{i1}, \cdots, x_{ip})^T\)</span> .</li>
</ul></li>
</ul></li>
<li><p>Goal: Find a function <span class="math inline">\(\hat{f}\)</span> such that <span class="math inline">\(Y\approx\hat{f}(X)\)</span> for any observation <span class="math inline">\((X,Y)\)</span> .</p></li>
<li><p>Most statistical methods for achieving this goal can be characterized as either <strong>parametric</strong> or <strong>non-parametric</strong>.</p></li>
</ul>
<section id="parametric-methods" class="level4">
<h4 class="anchored" data-anchor-id="parametric-methods">Parametric methods</h4>
<ul>
<li><p>Steps:</p>
<ol type="1">
<li>Make an assumption about the <strong>form</strong> of <span class="math inline">\(f\)</span>.<br>
It could be linear (<span class="math inline">\(f(X) = \beta_0 + \beta_1 X_1 + \cdot + \beta_p X_p,\)</span> parameters <span class="math inline">\(\beta_0, \cdots, \beta_p\)</span> to be estimated) or not.</li>
<li>The model has been selected.<br>
Now, we need a procedure to <strong>fit</strong> the model using the training data.<br>
The most common of such fitting procedures is called <strong>(ordinary) least squares</strong>.</li>
</ol></li>
<li><p>Via these steps, the problem of estimating <span class="math inline">\(f\)</span> has been reduced to a problem of estimating a <strong>set of parameters</strong>.</p></li>
<li><p>We can make the models more <strong>flexible</strong> via considering a greater number of parameters, but, this can lead to <strong>overfitting the data</strong>, that is, following the errors/noise too closely, which will not yield accurate estimates of the response for observations outside of the original training data.<br>
</p></li>
</ul>
</section>
<section id="non-parametric-methods" class="level4">
<h4 class="anchored" data-anchor-id="non-parametric-methods">Non-parametric methods</h4>
<ul>
<li>No assumptions about the form of <span class="math inline">\(f\)</span> are made.</li>
<li>Instead, we seek an estimate of <span class="math inline">\(f\)</span> which that gets as close to the data point as possible.</li>
<li>Has the potential to fit a wider range of possible forms for <span class="math inline">\(f\)</span>.</li>
<li>Tipically requires a very large number of observations (compared to paramatric approach) in order to accurately estimate <span class="math inline">\(f\)</span>.</li>
</ul>
</section>
</section>
<section id="the-trade-off-between-prediction-accuracy-and-model-interpretability" class="level3">
<h3 class="anchored" data-anchor-id="the-trade-off-between-prediction-accuracy-and-model-interpretability">The trade-off between prediction accuracy and model interpretability</h3>
<p>Weâ€™ve seen that parametric models are usually restrictive; and, non-parametric models, flexible. However:</p>
<ul>
<li><strong>Restrictive</strong> models are usually more <strong>interpretable</strong>, so they are useful for inference.</li>
<li><strong>Flexible</strong> models can be difficult to interpret, due to the complexity of <span class="math inline">\(\hat{f}\)</span>.</li>
</ul>
<p>Despite this, we will often obtain <strong>more accurate predictions</strong> usinf a <strong>less flexible method</strong>, due to the potential for <em>overfitting the data</em> in highly flexible models.</p>
</section>
<section id="supervised-vs-unsupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="supervised-vs-unsupervised-learning">Supervised vs Unsupervised Learning</h3>
<p>In <strong>supervised learning</strong>, we wish to fit a model that relates inputs/predictors to some output.</p>
<p>In <strong>unsupervised learning</strong>, we lack a reponse/variable to predict. Instead, we seek to understand the relationships between the variables or between the observations.</p>
<p>There are instances where a mix of such methods is required (<strong>semi-supervised learning problems</strong>), but such topic will not be covered in this book.</p>
</section>
<section id="regression-vs-classification-problems" class="level3">
<h3 class="anchored" data-anchor-id="regression-vs-classification-problems">Regression vs Classification problems</h3>
<ul>
<li>If the <strong>response is</strong> â€¦
<ul>
<li><strong>Quantitative</strong>, then, itâ€™s a regression problem.</li>
<li><strong>Categorical</strong>, then, itâ€™s a classification problem.</li>
</ul></li>
<li>Most of the methods covered in this book can be applied regardless of the predictor variable type, but the categorical variables will require some pre-processing.</li>
</ul>
</section>
</section>
<section id="assessing-model-accuracy" class="level2">
<h2 class="anchored" data-anchor-id="assessing-model-accuracy">Assessing model accuracy</h2>
<ul>
<li><p>There is no <strong>best method</strong> for Statistical Learning, the methodâ€™s efficacy can depend on the data set.</p></li>
<li><p>For a specific data set, <strong>how do we select the best Statistics approach</strong>?</p></li>
</ul>
<section id="measuring-the-quality-of-fit" class="level3">
<h3 class="anchored" data-anchor-id="measuring-the-quality-of-fit">Measuring the quality of fit</h3>
<ul>
<li><p>The performance of a statistical learning method can be evaluated comparing the predictions of the model, with their true/real response.</p></li>
<li><p>Most commonly used measure for this:</p>
<ul>
<li><strong>Mean squared error</strong></li>
<li><span class="math inline">\(\text{ MSE } = \dfrac{1}{n}\displaystyle{ \sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2 }\)</span></li>
<li>Small MSE means that the predicted and the true responses are very close.</li>
</ul></li>
<li><p>We want the model to accurately predict <strong>unseen data</strong> (testing data), not so much the training data, where the response is already known.</p></li>
<li><p>The <em>best</em> model will be the one which produces the <strong>lowest test MSE</strong>, not the lowest training MSE.</p></li>
<li><p>Itâ€™s <strong>not true</strong> that the model with lowest training MSE will also have the lowest test MSE.</p></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/02-train-test-MSE.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Training MSE vs Test MSE</figcaption>
</figure>
</div>
</div>
</div>
<ul>
<li><strong>Fundamental property</strong>: For any data set and any statistical learning method used, as the flexibility of the statistical learning method increases:
<ul>
<li>The training MSE decreases monotonically.</li>
<li>The test MSE graph has a <em>U</em>-shape.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>As model flexibility increases, training MSE will decrease, but the test MSE <strong>may not</strong>.</p>
</blockquote>
<ul>
<li><p>Small training MSE but big test MSE implies having overfitted the data.</p></li>
<li><p>Regardless of overfitting or not, we almost always expect <span class="math inline">\(\text{training MSE } &lt; \text{ testing MSE }\)</span>, beacuse most statistical learning methods seek to minimize the training MSE.</p></li>
<li><p>Estimating test MSE is very difficult, usually because lack of data. Later in this book, weâ€™ll discuss approaches to estimate the <strong>mininum point</strong> for the test MSE curve.</p></li>
</ul>
</section>
<section id="the-bias-variance-trade-off" class="level3">
<h3 class="anchored" data-anchor-id="the-bias-variance-trade-off">The Bias-Variance Trade-off</h3>
<ul>
<li><p><strong>Definition</strong>: The <strong>expected test MSE</strong> at <span class="math inline">\(x_0\)</span> (<span class="math inline">\(E(y_0 - \hat{f}(x_0))^2\)</span>) refers to the averga test MSE that we would obtain after repeatedly estimating <span class="math inline">\(f\)</span> using a large number of training sets, and tested each esimate at <span class="math inline">\(x_0\)</span>.</p></li>
<li><p><strong>Definition</strong>: The variance of a statistical learning method which produces an estimate <span class="math inline">\(\hat{f}\)</span> refers to how the estimate function changes, for different training sets.</p></li>
<li><p><strong>Definition</strong>: <strong>Bias</strong> refers to the error generated by approximating a possibly complicated model (like in real-life usually), by a much simpler one â€¦ (how <span class="math inline">\(f\)</span> and the possibles <span class="math inline">\(\hat{f}\)</span> <em>differ</em>).</p></li>
<li><p>As a general rule, the <strong>more flexible</strong> a statistical method, the <strong>higher its variance</strong> and <strong>lower its bias</strong>.</p></li>
<li><p>For any given value <span class="math inline">\(x_0\)</span>, the following can be proved:</p></li>
</ul>
<p><span class="math display">\[
E(y_0 - \hat{f}(x_0))^2 = \text{Var}(\hat{f}(x_0)) + \text{Bias}(\hat{f}(x_0))^2 + \text{ Var }(\epsilon)
\]</span></p>
<ul>
<li><p>Due to variance and squared bias being non negative, the previous equation implies that, to <strong>minimize the expected test error</strong>, we require a statistical learnig method which achieves <strong>low variance</strong> and <strong>low bias</strong>.</p></li>
<li><p>The tradeoff:</p>
<ul>
<li><em>Extremely low bias but high variance</em>: For example, draw a line which passes over every single point in the training data.</li>
<li><em>Extremely low variance but high bias</em>: For example, fit a horizontal line to the data.</li>
<li><blockquote class="blockquote">
<p>The challenge lies in finding a method for which both the variance and the squared bias are low.</p>
</blockquote></li>
</ul></li>
<li><p>In a real-life situation, <span class="math inline">\(f\)</span> is usually unkwon, so itâ€™s not possible to explicitly compute the test MSE, bias or variance of a statistical method.</p></li>
<li><p>The test MSE can be estimated using <strong>cross-validation</strong>, but weâ€™ll discuss it later in this book.</p></li>
</ul>
</section>
<section id="the-classification-setting" class="level3">
<h3 class="anchored" data-anchor-id="the-classification-setting">The Classification setting</h3>
<p>Letâ€™s see how the concepts recently discussed change when we the prediction is a categorical variable.</p>
<p>The most common approach for quantifying the accuracy of our estimate <span class="math inline">\(\hat{f}\)</span> is the <strong>training error rate</strong>, the proportion of mistakes made by applying <span class="math inline">\(\hat{f}\)</span> to the training observations:</p>
<p><span class="math display">\[
\dfrac{1}{n}\displaystyle{ \sum_{i=1}^{n} I(y_i \neq \hat{y}_i)}
\]</span></p>
<p>, where <span class="math inline">\(I\)</span> is <span class="math inline">\(1\)</span> when <span class="math inline">\(y_i = \hat{y}_i\)</span>, and <span class="math inline">\(0\)</span> otherwise.</p>
<ul>
<li><p>The <strong>test error rate</strong> is defined as <span class="math inline">\(\text{ Average}(I(y_i \neq \hat{y}_i))\)</span>, where the average is computed by comparing the predictions <span class="math inline">\(\hat{y}_i\)</span> with the true response <span class="math inline">\(y_i\)</span>.</p></li>
<li><p>A <strong>good classifier</strong> is one for which the test error is smallest.</p></li>
</ul>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/hastie\.su\.domains\/ISLP\/ISLP_website\.pdf");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./02_main.html" class="pagination-link" aria-label="2. Statistical Learning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">2. Statistical Learning</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./02_video.html" class="pagination-link" aria-label="Video">
        <span class="nav-page-text">Video</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1"></a><span class="fu"># Notes {-}</span></span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="fu">## What is Statistical Learning?</span></span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a>In this chapter will deal with</span>
<span id="cb1-6"><a href="#cb1-6"></a>developing an **accurate** model</span>
<span id="cb1-7"><a href="#cb1-7"></a>that can be used to **predict**</span>
<span id="cb1-8"><a href="#cb1-8"></a>some value.</span>
<span id="cb1-9"><a href="#cb1-9"></a></span>
<span id="cb1-10"><a href="#cb1-10"></a>Notation:</span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="ss">- </span>**Input variables**: $X_1, \cdots, X_p$  </span>
<span id="cb1-13"><a href="#cb1-13"></a>Also known as *predictors, features, independent variables*.</span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="ss">- </span>**Output variable**: $Y$  </span>
<span id="cb1-15"><a href="#cb1-15"></a>Also known as *response or dependent variable*.</span>
<span id="cb1-16"><a href="#cb1-16"></a></span>
<span id="cb1-17"><a href="#cb1-17"></a>We assume there is some relationship between</span>
<span id="cb1-18"><a href="#cb1-18"></a>$Y$ and $X = \left( X_1, \cdots, X_p \right)$, </span>
<span id="cb1-19"><a href="#cb1-19"></a>which we write as:</span>
<span id="cb1-20"><a href="#cb1-20"></a></span>
<span id="cb1-21"><a href="#cb1-21"></a>$$Y = f(X) + \epsilon$$</span>
<span id="cb1-22"><a href="#cb1-22"></a></span>
<span id="cb1-23"><a href="#cb1-23"></a>, where $\epsilon$ is a random **error term** which</span>
<span id="cb1-24"><a href="#cb1-24"></a>is **independent** from $X$ and has mean zero;</span>
<span id="cb1-25"><a href="#cb1-25"></a>and, $f$ represents the **systematic information** </span>
<span id="cb1-26"><a href="#cb1-26"></a>that $X$ provides about $Y$ .</span>
<span id="cb1-27"><a href="#cb1-27"></a></span>
<span id="cb1-30"><a href="#cb1-30"></a><span class="in">```{r}</span></span>
<span id="cb1-31"><a href="#cb1-31"></a><span class="co">#| label: 02-prediction</span></span>
<span id="cb1-32"><a href="#cb1-32"></a><span class="co">#| echo: false</span></span>
<span id="cb1-33"><a href="#cb1-33"></a><span class="co">#| fig-cap: Income data set</span></span>
<span id="cb1-34"><a href="#cb1-34"></a><span class="co">#| out-width: 100%</span></span>
<span id="cb1-35"><a href="#cb1-35"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"images/02-prediction.jpg"</span>)</span>
<span id="cb1-36"><a href="#cb1-36"></a><span class="in">```</span></span>
<span id="cb1-37"><a href="#cb1-37"></a></span>
<span id="cb1-38"><a href="#cb1-38"></a>In essence, statistical learning deals with **different approaches to estimate $f$** .</span>
<span id="cb1-39"><a href="#cb1-39"></a></span>
<span id="cb1-40"><a href="#cb1-40"></a><span class="fu">### Why estimate $f$?</span></span>
<span id="cb1-41"><a href="#cb1-41"></a></span>
<span id="cb1-42"><a href="#cb1-42"></a>Two main reasons to estimate $f$:</span>
<span id="cb1-43"><a href="#cb1-43"></a></span>
<span id="cb1-44"><a href="#cb1-44"></a><span class="fu">#### Prediction</span></span>
<span id="cb1-45"><a href="#cb1-45"></a></span>
<span id="cb1-46"><a href="#cb1-46"></a><span class="ss">- </span>Predict $Y$ using a set of inputs $X$ .</span>
<span id="cb1-47"><a href="#cb1-47"></a><span class="ss">- </span>Representation: $\hat{Y}= \hat{f}(X)$,</span>
<span id="cb1-48"><a href="#cb1-48"></a>where $\hat{f}$ represents our *estimate* for $f$,</span>
<span id="cb1-49"><a href="#cb1-49"></a>and $\hat{Y}$ our *prediction* for $Y$ .*</span>
<span id="cb1-50"><a href="#cb1-50"></a></span>
<span id="cb1-51"><a href="#cb1-51"></a><span class="ss">- </span>In this setting, $\hat{f}$ is often treated as a</span>
<span id="cb1-52"><a href="#cb1-52"></a>**black-box**, meaning we don't mind not knowing </span>
<span id="cb1-53"><a href="#cb1-53"></a>the exact form of $\hat{f}$, if it generates</span>
<span id="cb1-54"><a href="#cb1-54"></a>accurate predictions for $Y$ .</span>
<span id="cb1-55"><a href="#cb1-55"></a></span>
<span id="cb1-56"><a href="#cb1-56"></a><span class="ss">- </span>$\hat{Y}$'s accuracy depends on:</span>
<span id="cb1-57"><a href="#cb1-57"></a><span class="ss">    - </span>**Reducible error** </span>
<span id="cb1-58"><a href="#cb1-58"></a><span class="ss">        - </span>Due to $\hat{f}$ not being a perfect estimate for $f$.</span>
<span id="cb1-59"><a href="#cb1-59"></a><span class="ss">        - </span>**Can be reduced** by using a proper statistical learning technique.</span>
<span id="cb1-60"><a href="#cb1-60"></a><span class="ss">    - </span>**Irreducible error** </span>
<span id="cb1-61"><a href="#cb1-61"></a><span class="ss">        - </span>Due to $\epsilon$ and its variability.</span>
<span id="cb1-62"><a href="#cb1-62"></a><span class="ss">        - </span>$\epsilon$ is independent from $X$, so  no matter</span>
<span id="cb1-63"><a href="#cb1-63"></a>        how well we estimate $f$, we can't reduce this error.</span>
<span id="cb1-64"><a href="#cb1-64"></a></span>
<span id="cb1-65"><a href="#cb1-65"></a><span class="ss">- </span>The quantity $\epsilon$ may contain **unmeasured variables** </span>
<span id="cb1-66"><a href="#cb1-66"></a>useful for predicting $Y$; or, may contain **unmeasure variation**,</span>
<span id="cb1-67"><a href="#cb1-67"></a>so no prediction model will be perfect.</span>
<span id="cb1-68"><a href="#cb1-68"></a></span>
<span id="cb1-69"><a href="#cb1-69"></a><span class="ss">- </span>Mathematical form, after choosing predictors $X$ and an estimate</span>
<span id="cb1-70"><a href="#cb1-70"></a>$\hat{f}$:</span>
<span id="cb1-71"><a href="#cb1-71"></a></span>
<span id="cb1-72"><a href="#cb1-72"></a>$$</span>
<span id="cb1-73"><a href="#cb1-73"></a>E( Y - \hat{Y} )^2 =</span>
<span id="cb1-74"><a href="#cb1-74"></a>E(f(X) + \epsilon - \hat{f}(X))^2 =</span>
<span id="cb1-75"><a href="#cb1-75"></a>\underbrace{<span class="co">[</span><span class="ot">f(X) - \hat{f}(X)</span><span class="co">]</span>^2}_{reducible} +</span>
<span id="cb1-76"><a href="#cb1-76"></a>\underbrace{\text{ Var}(\epsilon)}_{irreducible}\; .</span>
<span id="cb1-77"><a href="#cb1-77"></a>$$ </span>
<span id="cb1-78"><a href="#cb1-78"></a></span>
<span id="cb1-79"><a href="#cb1-79"></a>In practice, we almost always don't know how </span>
<span id="cb1-80"><a href="#cb1-80"></a>$\epsilon$'s variability affects our model,</span>
<span id="cb1-81"><a href="#cb1-81"></a>so, in this book, we will focus on techniques for estimating $f$ .</span>
<span id="cb1-82"><a href="#cb1-82"></a></span>
<span id="cb1-83"><a href="#cb1-83"></a><span class="fu">#### Inference</span></span>
<span id="cb1-84"><a href="#cb1-84"></a></span>
<span id="cb1-85"><a href="#cb1-85"></a>In this case, we are interested in **understanding the association** </span>
<span id="cb1-86"><a href="#cb1-86"></a>between $Y$ and $X_1, \cdots, X_p$.</span>
<span id="cb1-87"><a href="#cb1-87"></a></span>
<span id="cb1-88"><a href="#cb1-88"></a><span class="ss">- </span>For example:</span>
<span id="cb1-89"><a href="#cb1-89"></a><span class="ss">    - </span>*Which predictors are most associated with response?*</span>
<span id="cb1-90"><a href="#cb1-90"></a><span class="ss">    - </span>*What is the relationship between the response and each predictor?*</span>
<span id="cb1-91"><a href="#cb1-91"></a><span class="ss">    - </span>*Can such relationship be summarized via a linear equation, or is it more complex?*</span>
<span id="cb1-92"><a href="#cb1-92"></a></span>
<span id="cb1-93"><a href="#cb1-93"></a>The exact form of $\hat{f}$ is required.</span>
<span id="cb1-94"><a href="#cb1-94"></a></span>
<span id="cb1-95"><a href="#cb1-95"></a>Linear models allow for easier interpretability, but </span>
<span id="cb1-96"><a href="#cb1-96"></a>can lack in prediction accuracy; while,</span>
<span id="cb1-97"><a href="#cb1-97"></a>non-linear models can be more accurate, but less interpretable.</span>
<span id="cb1-98"><a href="#cb1-98"></a></span>
<span id="cb1-99"><a href="#cb1-99"></a><span class="fu">### How do we estimate $f$ ?</span></span>
<span id="cb1-100"><a href="#cb1-100"></a></span>
<span id="cb1-101"><a href="#cb1-101"></a><span class="ss">- </span>First, let's agree on some conventions:</span>
<span id="cb1-102"><a href="#cb1-102"></a><span class="ss">    - </span>$n$ : Number of observations.</span>
<span id="cb1-103"><a href="#cb1-103"></a><span class="ss">    - </span>$x_{ij}$: Value of the $j\text{th}$ predictor, for $i\text{th}$ observation.</span>
<span id="cb1-104"><a href="#cb1-104"></a><span class="ss">    - </span>$y_i$ : Response variable for $i\text{th}$ observation.</span>
<span id="cb1-105"><a href="#cb1-105"></a><span class="ss">    - </span>**Training data**: </span>
<span id="cb1-106"><a href="#cb1-106"></a><span class="ss">        - </span>Set of observations.</span>
<span id="cb1-107"><a href="#cb1-107"></a><span class="ss">        - </span>Used to esmitate $f$.</span>
<span id="cb1-108"><a href="#cb1-108"></a><span class="ss">        - </span>$\left<span class="sc">\{</span> (x_1, y_1), \cdots, (x_n, y_n) \right<span class="sc">\}</span>$,</span>
<span id="cb1-109"><a href="#cb1-109"></a>        where $x_i = (x_{i1}, \cdots, x_{ip})^T$ .</span>
<span id="cb1-110"><a href="#cb1-110"></a>  </span>
<span id="cb1-111"><a href="#cb1-111"></a><span class="ss">- </span>Goal: Find a function $\hat{f}$ such that $Y\approx\hat{f}(X)$ </span>
<span id="cb1-112"><a href="#cb1-112"></a>for any observation $(X,Y)$ .</span>
<span id="cb1-113"><a href="#cb1-113"></a></span>
<span id="cb1-114"><a href="#cb1-114"></a><span class="ss">- </span>Most statistical methods for achieving this goal can be</span>
<span id="cb1-115"><a href="#cb1-115"></a>characterized as either **parametric** or **non-parametric**.</span>
<span id="cb1-116"><a href="#cb1-116"></a></span>
<span id="cb1-117"><a href="#cb1-117"></a><span class="fu">#### Parametric methods</span></span>
<span id="cb1-118"><a href="#cb1-118"></a></span>
<span id="cb1-119"><a href="#cb1-119"></a><span class="ss">- </span>Steps:</span>
<span id="cb1-120"><a href="#cb1-120"></a><span class="ss">    1. </span>Make an assumption about the **form** of $f$. \</span>
<span id="cb1-121"><a href="#cb1-121"></a>    It could be linear </span>
<span id="cb1-122"><a href="#cb1-122"></a>    ($f(X) = \beta_0 + \beta_1 X_1 + \cdot + \beta_p X_p,$ </span>
<span id="cb1-123"><a href="#cb1-123"></a>    parameters $\beta_0, \cdots, \beta_p$ to be estimated) or not.</span>
<span id="cb1-124"><a href="#cb1-124"></a><span class="ss">    1. </span>The model has been selected. \</span>
<span id="cb1-125"><a href="#cb1-125"></a>    Now, we need a procedure to **fit** the model using the training data. \</span>
<span id="cb1-126"><a href="#cb1-126"></a>    The most common of such fitting procedures is called </span>
<span id="cb1-127"><a href="#cb1-127"></a>    **(ordinary) least squares**.</span>
<span id="cb1-128"><a href="#cb1-128"></a></span>
<span id="cb1-129"><a href="#cb1-129"></a><span class="ss">- </span>Via these steps, the problem of estimating $f$ has been reduced</span>
<span id="cb1-130"><a href="#cb1-130"></a>to a problem of estimating a **set of  parameters**.</span>
<span id="cb1-131"><a href="#cb1-131"></a></span>
<span id="cb1-132"><a href="#cb1-132"></a><span class="ss">- </span>We can make the models more **flexible** via considering a </span>
<span id="cb1-133"><a href="#cb1-133"></a>greater number of parameters, but, this can lead to **overfitting the data**, that is, following the errors/noise too closely, </span>
<span id="cb1-134"><a href="#cb1-134"></a>which will not yield accurate estimates of the response for </span>
<span id="cb1-135"><a href="#cb1-135"></a>observations outside of the original training data. \</span>
<span id="cb1-136"><a href="#cb1-136"></a></span>
<span id="cb1-137"><a href="#cb1-137"></a><span class="fu">#### Non-parametric methods</span></span>
<span id="cb1-138"><a href="#cb1-138"></a></span>
<span id="cb1-139"><a href="#cb1-139"></a><span class="ss">- </span>No assumptions about the form of $f$ are made.</span>
<span id="cb1-140"><a href="#cb1-140"></a><span class="ss">- </span>Instead, we seek an estimate of $f$ which </span>
<span id="cb1-141"><a href="#cb1-141"></a>that gets as close to the data point as possible.</span>
<span id="cb1-142"><a href="#cb1-142"></a><span class="ss">- </span>Has the potential to fit a wider range of possible forms for $f$.</span>
<span id="cb1-143"><a href="#cb1-143"></a><span class="ss">- </span>Tipically requires a very large number of observations</span>
<span id="cb1-144"><a href="#cb1-144"></a>(compared to paramatric approach) in order to accurately estimate $f$.</span>
<span id="cb1-145"><a href="#cb1-145"></a></span>
<span id="cb1-146"><a href="#cb1-146"></a></span>
<span id="cb1-147"><a href="#cb1-147"></a><span class="fu">### The trade-off between prediction accuracy and model interpretability</span></span>
<span id="cb1-148"><a href="#cb1-148"></a></span>
<span id="cb1-149"><a href="#cb1-149"></a>We've seen that parametric models are usually restrictive; and,</span>
<span id="cb1-150"><a href="#cb1-150"></a>non-parametric models, flexible. However:</span>
<span id="cb1-151"><a href="#cb1-151"></a></span>
<span id="cb1-152"><a href="#cb1-152"></a><span class="ss">- </span>**Restrictive** models are usually more **interpretable**,</span>
<span id="cb1-153"><a href="#cb1-153"></a>so they are useful for inference.</span>
<span id="cb1-154"><a href="#cb1-154"></a><span class="ss">- </span>**Flexible** models can be difficult to interpret, due to</span>
<span id="cb1-155"><a href="#cb1-155"></a>the complexity of $\hat{f}$.</span>
<span id="cb1-156"><a href="#cb1-156"></a></span>
<span id="cb1-157"><a href="#cb1-157"></a>Despite this, we will often obtain **more accurate predictions** </span>
<span id="cb1-158"><a href="#cb1-158"></a>usinf a **less flexible method**, due to the potential for</span>
<span id="cb1-159"><a href="#cb1-159"></a>*overfitting the data* in highly flexible models.</span>
<span id="cb1-160"><a href="#cb1-160"></a></span>
<span id="cb1-161"><a href="#cb1-161"></a><span class="fu">### Supervised vs Unsupervised Learning</span></span>
<span id="cb1-162"><a href="#cb1-162"></a></span>
<span id="cb1-163"><a href="#cb1-163"></a>In **supervised learning**, we wish to fit a model</span>
<span id="cb1-164"><a href="#cb1-164"></a>that relates inputs/predictors to some output.</span>
<span id="cb1-165"><a href="#cb1-165"></a></span>
<span id="cb1-166"><a href="#cb1-166"></a>In **unsupervised learning**, we lack a reponse/variable</span>
<span id="cb1-167"><a href="#cb1-167"></a>to predict. Instead, we seek to understand the relationships</span>
<span id="cb1-168"><a href="#cb1-168"></a>between the variables or between the observations.</span>
<span id="cb1-169"><a href="#cb1-169"></a></span>
<span id="cb1-170"><a href="#cb1-170"></a>There are instances where a mix of such methods is required</span>
<span id="cb1-171"><a href="#cb1-171"></a>(**semi-supervised learning problems**), but such topic</span>
<span id="cb1-172"><a href="#cb1-172"></a>will not be covered in this book.</span>
<span id="cb1-173"><a href="#cb1-173"></a></span>
<span id="cb1-174"><a href="#cb1-174"></a><span class="fu">### Regression vs Classification problems</span></span>
<span id="cb1-175"><a href="#cb1-175"></a></span>
<span id="cb1-176"><a href="#cb1-176"></a><span class="ss">- </span>If the **response is** ...</span>
<span id="cb1-177"><a href="#cb1-177"></a><span class="ss">    - </span>**Quantitative**, then, it's a regression problem.</span>
<span id="cb1-178"><a href="#cb1-178"></a><span class="ss">    - </span>**Categorical**, then, it's a classification problem.</span>
<span id="cb1-179"><a href="#cb1-179"></a></span>
<span id="cb1-180"><a href="#cb1-180"></a><span class="ss">- </span>Most of the methods covered in this book can be applied</span>
<span id="cb1-181"><a href="#cb1-181"></a>regardless of the predictor variable type, but the categorical</span>
<span id="cb1-182"><a href="#cb1-182"></a>variables will require some pre-processing.</span>
<span id="cb1-183"><a href="#cb1-183"></a></span>
<span id="cb1-184"><a href="#cb1-184"></a><span class="fu">## Assessing model accuracy</span></span>
<span id="cb1-185"><a href="#cb1-185"></a></span>
<span id="cb1-186"><a href="#cb1-186"></a><span class="ss">- </span>There is no **best method** for Statistical Learning, </span>
<span id="cb1-187"><a href="#cb1-187"></a>the method's efficacy can depend on the data set.</span>
<span id="cb1-188"><a href="#cb1-188"></a></span>
<span id="cb1-189"><a href="#cb1-189"></a><span class="ss">- </span>For a specific data set, **how do we select the best Statistics approach**?</span>
<span id="cb1-190"><a href="#cb1-190"></a></span>
<span id="cb1-191"><a href="#cb1-191"></a><span class="fu">### Measuring the quality of fit</span></span>
<span id="cb1-192"><a href="#cb1-192"></a></span>
<span id="cb1-193"><a href="#cb1-193"></a><span class="ss">- </span>The performance of a statistical learning method can be evaluated</span>
<span id="cb1-194"><a href="#cb1-194"></a>comparing the predictions of the model, with their true/real response.</span>
<span id="cb1-195"><a href="#cb1-195"></a></span>
<span id="cb1-196"><a href="#cb1-196"></a><span class="ss">- </span>Most commonly used measure for this:</span>
<span id="cb1-197"><a href="#cb1-197"></a><span class="ss">    - </span>**Mean squared error** </span>
<span id="cb1-198"><a href="#cb1-198"></a><span class="ss">    - </span>$\text{ MSE } = \dfrac{1}{n}\displaystyle{ \sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2 }$ </span>
<span id="cb1-199"><a href="#cb1-199"></a><span class="ss">    - </span>Small MSE means that the predicted and the true responses are very close.</span>
<span id="cb1-200"><a href="#cb1-200"></a></span>
<span id="cb1-201"><a href="#cb1-201"></a><span class="ss">- </span>We want the model to accurately predict **unseen data** (testing data),</span>
<span id="cb1-202"><a href="#cb1-202"></a>not so much the training data, where the response is already known.</span>
<span id="cb1-203"><a href="#cb1-203"></a></span>
<span id="cb1-204"><a href="#cb1-204"></a><span class="ss">- </span>The *best* model will be the one which produces the **lowest test MSE**,</span>
<span id="cb1-205"><a href="#cb1-205"></a>not the lowest training MSE.</span>
<span id="cb1-206"><a href="#cb1-206"></a></span>
<span id="cb1-207"><a href="#cb1-207"></a><span class="ss">- </span>It's **not true** that the model with lowest training MSE will also</span>
<span id="cb1-208"><a href="#cb1-208"></a>have the lowest test MSE.</span>
<span id="cb1-209"><a href="#cb1-209"></a></span>
<span id="cb1-212"><a href="#cb1-212"></a><span class="in">```{r}</span></span>
<span id="cb1-213"><a href="#cb1-213"></a><span class="co">#| label: 02-train-test-MSE</span></span>
<span id="cb1-214"><a href="#cb1-214"></a><span class="co">#| echo: false</span></span>
<span id="cb1-215"><a href="#cb1-215"></a><span class="co">#| fig-cap: Training MSE vs Test MSE</span></span>
<span id="cb1-216"><a href="#cb1-216"></a><span class="co">#| out-width: 100%</span></span>
<span id="cb1-217"><a href="#cb1-217"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"images/02-train-test-MSE.jpg"</span>)</span>
<span id="cb1-218"><a href="#cb1-218"></a><span class="in">```</span></span>
<span id="cb1-219"><a href="#cb1-219"></a></span>
<span id="cb1-220"><a href="#cb1-220"></a><span class="ss">- </span>**Fundamental property**: For any data set and any statistical learning method used, as the flexibility of the statistical learning method increases:</span>
<span id="cb1-221"><a href="#cb1-221"></a><span class="ss">    - </span>The training MSE decreases monotonically.</span>
<span id="cb1-222"><a href="#cb1-222"></a><span class="ss">    - </span>The test MSE graph has a *U*-shape.</span>
<span id="cb1-223"><a href="#cb1-223"></a></span>
<span id="cb1-224"><a href="#cb1-224"></a><span class="at">&gt; As model flexibility increases, training MSE will decrease,</span></span>
<span id="cb1-225"><a href="#cb1-225"></a><span class="at">&gt; but the test MSE **may not**.</span></span>
<span id="cb1-226"><a href="#cb1-226"></a></span>
<span id="cb1-227"><a href="#cb1-227"></a><span class="ss">- </span>Small training MSE but big test MSE implies having overfitted the data.</span>
<span id="cb1-228"><a href="#cb1-228"></a></span>
<span id="cb1-229"><a href="#cb1-229"></a><span class="ss">- </span>Regardless of overfitting or not, we almost always expect </span>
<span id="cb1-230"><a href="#cb1-230"></a>$\text{training MSE } &lt; \text{ testing MSE }$, beacuse most statistical learning methods seek to minimize the training MSE.</span>
<span id="cb1-231"><a href="#cb1-231"></a></span>
<span id="cb1-232"><a href="#cb1-232"></a><span class="ss">- </span>Estimating test MSE is very difficult, usually because lack of data.</span>
<span id="cb1-233"><a href="#cb1-233"></a>Later in this book, we'll discuss approaches to estimate the </span>
<span id="cb1-234"><a href="#cb1-234"></a>**mininum point** for the test MSE curve.</span>
<span id="cb1-235"><a href="#cb1-235"></a></span>
<span id="cb1-236"><a href="#cb1-236"></a><span class="fu">### The Bias-Variance Trade-off</span></span>
<span id="cb1-237"><a href="#cb1-237"></a></span>
<span id="cb1-238"><a href="#cb1-238"></a><span class="ss">- </span>**Definition**: The **expected test MSE** at $x_0$ </span>
<span id="cb1-239"><a href="#cb1-239"></a>($E(y_0 - \hat{f}(x_0))^2$) refers to </span>
<span id="cb1-240"><a href="#cb1-240"></a>the averga test MSE that we would obtain after repeatedly estimating</span>
<span id="cb1-241"><a href="#cb1-241"></a>$f$ using a large number of training sets, and tested each esimate</span>
<span id="cb1-242"><a href="#cb1-242"></a>at $x_0$.</span>
<span id="cb1-243"><a href="#cb1-243"></a></span>
<span id="cb1-244"><a href="#cb1-244"></a><span class="ss">- </span>**Definition**: The variance of a statistical learning method which</span>
<span id="cb1-245"><a href="#cb1-245"></a>produces an estimate $\hat{f}$ refers to how the estimate function</span>
<span id="cb1-246"><a href="#cb1-246"></a>changes, for different training sets.</span>
<span id="cb1-247"><a href="#cb1-247"></a></span>
<span id="cb1-248"><a href="#cb1-248"></a><span class="ss">- </span>**Definition**: **Bias** refers to the error generated by approximating</span>
<span id="cb1-249"><a href="#cb1-249"></a>a possibly complicated model (like in real-life usually), by a much simpler one ... (how $f$ and the possibles $\hat{f}$ *differ*).</span>
<span id="cb1-250"><a href="#cb1-250"></a></span>
<span id="cb1-251"><a href="#cb1-251"></a><span class="ss">- </span>As a general rule, the **more flexible** a statistical method, </span>
<span id="cb1-252"><a href="#cb1-252"></a>the **higher its variance** and **lower its bias**.</span>
<span id="cb1-253"><a href="#cb1-253"></a></span>
<span id="cb1-254"><a href="#cb1-254"></a><span class="ss">- </span>For any given value $x_0$, the following can be proved:</span>
<span id="cb1-255"><a href="#cb1-255"></a></span>
<span id="cb1-256"><a href="#cb1-256"></a>$$</span>
<span id="cb1-257"><a href="#cb1-257"></a>E(y_0 - \hat{f}(x_0))^2 = \text{Var}(\hat{f}(x_0)) + \text{Bias}(\hat{f}(x_0))^2 + \text{ Var }(\epsilon)</span>
<span id="cb1-258"><a href="#cb1-258"></a>$$</span>
<span id="cb1-259"><a href="#cb1-259"></a></span>
<span id="cb1-260"><a href="#cb1-260"></a></span>
<span id="cb1-261"><a href="#cb1-261"></a><span class="ss">- </span>Due to variance and squared bias being non negative, the previous equation</span>
<span id="cb1-262"><a href="#cb1-262"></a>implies that, to **minimize the expected test error**, we require a</span>
<span id="cb1-263"><a href="#cb1-263"></a>statistical learnig method which achieves **low variance** and **low bias**.</span>
<span id="cb1-264"><a href="#cb1-264"></a></span>
<span id="cb1-265"><a href="#cb1-265"></a><span class="ss">- </span>The tradeoff:</span>
<span id="cb1-266"><a href="#cb1-266"></a><span class="ss">    - </span>*Extremely low bias but high variance*: For example, draw a line which passes over every single point in the training data.</span>
<span id="cb1-267"><a href="#cb1-267"></a><span class="ss">    - </span>*Extremely low variance but high bias*: For example, fit a</span>
<span id="cb1-268"><a href="#cb1-268"></a>    horizontal line to the data.</span>
<span id="cb1-269"><a href="#cb1-269"></a><span class="ss">    - </span>&gt; The challenge lies in finding</span>
<span id="cb1-270"><a href="#cb1-270"></a><span class="at">      &gt; a method for which both the variance and the squared bias are low.</span></span>
<span id="cb1-271"><a href="#cb1-271"></a></span>
<span id="cb1-272"><a href="#cb1-272"></a><span class="ss">- </span>In a real-life situation, $f$ is usually unkwon, so it's not possible </span>
<span id="cb1-273"><a href="#cb1-273"></a>to explicitly compute the test MSE, bias or variance of a statistical method.</span>
<span id="cb1-274"><a href="#cb1-274"></a></span>
<span id="cb1-275"><a href="#cb1-275"></a><span class="ss">- </span>The test MSE can be estimated using **cross-validation**,</span>
<span id="cb1-276"><a href="#cb1-276"></a>but we'll discuss it later in this book.</span>
<span id="cb1-277"><a href="#cb1-277"></a></span>
<span id="cb1-278"><a href="#cb1-278"></a><span class="fu">### The Classification setting</span></span>
<span id="cb1-279"><a href="#cb1-279"></a></span>
<span id="cb1-280"><a href="#cb1-280"></a>Let's see how the concepts recently discussed change</span>
<span id="cb1-281"><a href="#cb1-281"></a>when we the prediction is a categorical variable.</span>
<span id="cb1-282"><a href="#cb1-282"></a></span>
<span id="cb1-283"><a href="#cb1-283"></a>The most common approach for quantifying the accuracy</span>
<span id="cb1-284"><a href="#cb1-284"></a>of our estimate $\hat{f}$ is the **training error rate**,</span>
<span id="cb1-285"><a href="#cb1-285"></a>the proportion of mistakes made by applying $\hat{f}$ </span>
<span id="cb1-286"><a href="#cb1-286"></a>to the training observations:</span>
<span id="cb1-287"><a href="#cb1-287"></a></span>
<span id="cb1-288"><a href="#cb1-288"></a>$$</span>
<span id="cb1-289"><a href="#cb1-289"></a>\dfrac{1}{n}\displaystyle{ \sum_{i=1}^{n} I(y_i \neq \hat{y}_i)}</span>
<span id="cb1-290"><a href="#cb1-290"></a>$$</span>
<span id="cb1-291"><a href="#cb1-291"></a></span>
<span id="cb1-292"><a href="#cb1-292"></a>, where $I$ is $1$ when $y_i = \hat{y}_i$, and $0$ otherwise.</span>
<span id="cb1-293"><a href="#cb1-293"></a></span>
<span id="cb1-294"><a href="#cb1-294"></a><span class="ss">- </span>The **test error rate** is defined as</span>
<span id="cb1-295"><a href="#cb1-295"></a>$\text{ Average}(I(y_i \neq \hat{y}_i))$, where the average</span>
<span id="cb1-296"><a href="#cb1-296"></a>is computed by comparing the predictions $\hat{y}_i$ with the</span>
<span id="cb1-297"><a href="#cb1-297"></a>true response $y_i$. </span>
<span id="cb1-298"><a href="#cb1-298"></a></span>
<span id="cb1-299"><a href="#cb1-299"></a><span class="ss">- </span>A **good classifier** is one for which the test error is smallest.</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>